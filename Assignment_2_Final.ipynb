{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc25b03",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7906b38",
   "metadata": {},
   "source": [
    "### Group Members:\n",
    "\n",
    "#### Anagha Vinayak Kamat (22220809)\n",
    "#### Matthew McKernan (17321381)\n",
    "#### Leelakrishna Sala (22224577)\n",
    "\n",
    "\n",
    "In the assignment, data fetching and creating trainable and testable data is carried out by Anagha Vinayak Kamat with little improvisations by Matthew. The custom layer implementation and combining it with the existing pytorch CNN was done by Matthew McKernan. Matthew wrote an initial proof of concept as a class with just a forward pass of the initial proposed layer. He also wrote a class in pytorch with a forward and backward pass and tested if the layer works on a random array. All three of us have tried to train and test the network on the alpaca dataset. Matthew could achieve the succesful implementation of it. Because we were not able to generate the epochs graph of loss and accuracy with our custom layer, we decided to implement basic CNN with different parameters and compare the final accuracy score and loss with the results achieved from the custom CNN. Leela and Anagha worked on building the basic CNN layer models and Leela gave the final comparison results in the form of table. For the final report all three of us sat together and build the entire report. We implemented the tensorboard for basic conv2D. The idea and code for the same was put by Leela. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94836eff",
   "metadata": {},
   "source": [
    "# How did we implement the layer within existing library (keras, TensorFlow, PyTorch, or other)\n",
    "\n",
    "We made sure that the weight matrix had the same shape as the input map in the forward pass. The receptive field is then applied to the input feature map and the weights matrix in the same way creating receptive_field and receptive_field_weights. The dot product of these two matrices then gave the result for the output feature map. Three nested for loops were used to generate the output feature map for the RGB images. The receptive field moves across the input feature map and weights matrix in the same way until the output feature layer is completed.\n",
    "\n",
    "Tested the custom layer on a random array and it returned results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f23f8",
   "metadata": {},
   "source": [
    "## Anagha's Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5b4743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "# Step 1: Load and preprocess image data\n",
    "\n",
    "input1 = 'alpaca/'\n",
    "filename1 = []\n",
    "for filename in os.listdir(input1):                   # reading the directiry\n",
    "    filename1.append(input1 + filename)               # storing the file name data\n",
    "\n",
    "input2 = 'not alpaca/'\n",
    "filename2 = []\n",
    "for filename in os.listdir(input2):\n",
    "    filename2.append(input2 + filename)\n",
    "\n",
    "\n",
    "# Initially Anagha created the dataframe which stored all the image file name in the data frame and labelled as yes and no \n",
    "# for alpaca and not alpaca. But because the data was not in the array format Matthew carried out the image array conversion part\n",
    "# and generated 1 and 0 values for alpaca and not alpaca respectively. \n",
    "    \n",
    "\n",
    "# Load and preprocess images\n",
    "# Matthew's improvisation start\n",
    "def load_and_preprocess_image(filename):\n",
    "    image = cv2.imread(filename)                                                #reading the image data\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)                              # Convert from BGR to RGB \n",
    "    image = cv2.resize(image, (32, 32))                                         # Resize to 32x32\n",
    "    image = image.astype('float32') / 255.0                                     # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "X1 = np.array([load_and_preprocess_image(filename) for filename in filename1])\n",
    "Y1 = np.ones(len(X1), dtype=np.int32)                                           # generate 1\n",
    "\n",
    "X2 = np.array([load_and_preprocess_image(filename) for filename in filename2])\n",
    "Y2 = np.zeros(len(X2), dtype=np.int32)                                          # generate 2\n",
    "# Matthew's improvisation ends\n",
    "\n",
    "# Concatenate and split data\n",
    "X = np.concatenate((X1, X2), axis=0)                                            # combining the training data\n",
    "Y = np.concatenate((Y1, Y2), axis=0)                                            # combining the testing data\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.50, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9f4c9",
   "metadata": {},
   "source": [
    "## Matthew's Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd11e4",
   "metadata": {},
   "source": [
    "### Custom Layer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layered network\n",
    "\n",
    "class ConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, input_size, num_channels, filter_size):\n",
    "        super(ConvolutionalLayer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_channels = num_channels\n",
    "        self.filter_size = filter_size\n",
    "        self.output_size = (input_size[0] - filter_size[0] + 1, input_size[1] - filter_size[1] + 1)\n",
    "        self.output_feature_map = torch.zeros((self.num_channels, self.output_size[0], self.output_size[1]))\n",
    "\n",
    "    def forward(self, input_feature_map):\n",
    "        batch_size = input_feature_map.size(0)\n",
    "        self.weight_matrix = nn.Parameter(torch.randn(input_feature_map.size(0), input_feature_map.size(1), input_feature_map.size(2), input_feature_map.size(3)))\n",
    "        output_feature_maps = []\n",
    "        #in_channels = input_feature_map.shape[1]        # Check if the number of filters matches the number of input channels\n",
    "        #assert self.num_channels == in_channels, \"Number of filters must match the number of input channels\"\n",
    "    #following line to check if input_fm and weights same shape   \n",
    "        #print('input_f_m: ', np.shape(input_feature_map), 'weights: ', np.shape(self.weight_matrix))\n",
    "        for i in range(batch_size):\n",
    "            output_feature_map = torch.zeros((self.num_channels, self.output_size[0], self.output_size[1]))\n",
    "            for k in range(self.num_channels):\n",
    "                for j in range(self.output_size[0]):\n",
    "                    for l in range(self.output_size[1]):\n",
    "                        #the same receptive field is applied to the weights as the input\n",
    "                        receptive_field = input_feature_map[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        receptive_field_weight = self.weight_matrix[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        #print(l, 'rf:', np.shape(receptive_field), 'rfw: ', np.shape(receptive_field_weight))\n",
    "                        weighted_output = torch.sum(receptive_field * receptive_field_weight, dim=(1,2))\n",
    "                        output_feature_map[k, j, l] = weighted_output[k]\n",
    "            output_feature_maps.append(output_feature_map)\n",
    "        output_feature_maps = torch.stack(output_feature_maps, dim=0)\n",
    "        return output_feature_maps\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        batch_size = grad_output.size(0)\n",
    "        grad_input = torch.zeros((batch_size, self.input_size[0], self.input_size[1], self.filter_size[0], self.filter_size[1]), device=self.weight_matrix.device)\n",
    "        grad_weight = torch.zeros_like(self.weight_matrix)\n",
    "        for i in range(batch_size):\n",
    "            for k in range(self.num_channels):\n",
    "                for j in range(self.output_size[0]):\n",
    "                    for l in range(self.output_size[1]):\n",
    "                        # compute the gradient of the output w.r.t. the receptive field\n",
    "                        grad_weight[k] += grad_output[i, k, j, l] * self.input_feature_map[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        # compute the gradient of the output w.r.t. the input feature map\n",
    "                        grad_input[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]] += grad_output[i, k, j, l] * self.weight_matrix[k]\n",
    "        self.weight_matrix.grad = torch.sum(grad_weight, dim=0, keepdim=True)\n",
    "        return grad_input\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edbb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 3 layers Implementation\n",
    "\n",
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = ConvolutionalLayer(input_size=(32,32), num_channels=16, filter_size=(3, 3))\n",
    "        self.conv2 = ConvolutionalLayer(input_size=(32,32), num_channels=12, filter_size=(3, 3))\n",
    "        self.conv3 = ConvolutionalLayer(input_size=(32,32), num_channels=8, filter_size=(3, 3))\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(1800, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.output_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('Input shape:', x.shape)\n",
    "        # apply relu activation to each conv layer and then pool using 2x2\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1) # flatten the array\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.output_activation(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "model = CNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_classes=2\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train() # Set the model to training mode\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels = labels.long()\n",
    "        #labels = F.one_hot(labels, num_classes)\n",
    "        #labels = F.one_hot(torch.argmax(labels, dim=1), num_classes)\n",
    "        #print(labels, outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(preds == labels.long())\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = train_acc.float() / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_acc += torch.sum(preds == labels.long())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_acc.float() / len(val_loader.dataset)\n",
    "\n",
    "    # Print the loss and accuracy for this epoch\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e16051d",
   "metadata": {},
   "source": [
    "This code ran when I printed out the shape of x in the forward loop. However, it took too long to run on our laptops. We tried to keep our laptops on, but even after an hour one epoch hadn't even completed. We then attempted an approach with just one convolutional layer to see if it sped up the result. It sped training a bit, but did not give good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f646b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer custom model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#labels = F.one_hot(labels, num_classes)\n",
    "\n",
    "\n",
    "class ConvolutionalLayer(nn.Module):\n",
    "    def __init__(self, input_size, num_channels, filter_size):\n",
    "        super(ConvolutionalLayer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_channels = num_channels\n",
    "        self.filter_size = filter_size\n",
    "        #make weights matrix the same size as the input\n",
    "        self.weight_matrix = nn.Parameter(torch.randn(batch_size, 32, 32, 3))\n",
    "        self.output_size = (input_size[0] - filter_size[0] + 1, input_size[1] - filter_size[1] + 1)\n",
    "        self.output_feature_map = torch.zeros((self.num_channels, self.output_size[0], self.output_size[1]))\n",
    "\n",
    "    def forward(self, input_feature_map):\n",
    "        batch_size = input_feature_map.size(0)\n",
    "        output_feature_maps = []\n",
    "        #in_channels = input_feature_map.shape[1]        # Check if the number of filters matches the number of input channels\n",
    "        #assert self.num_channels == in_channels, \"Number of filters must match the number of input channels\"\n",
    "    #following line to check if input_fm and weights same shape   \n",
    "    # print('input_f_m: ', np.shape(input_feature_map), 'weights: ', np.shape(self.weight_matrix))\n",
    "        for i in range(batch_size):\n",
    "            output_feature_map = torch.zeros((self.num_channels, self.output_size[0], self.output_size[1]))\n",
    "            for k in range(self.num_channels):\n",
    "                for j in range(self.output_size[0]):\n",
    "                    for l in range(self.output_size[1]):\n",
    "                        #the same receptive field is applied to the weights as the input\n",
    "                        receptive_field = input_feature_map[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        receptive_field_weight = self.weight_matrix[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                       \n",
    "                       # print(l, 'rf:', np.shape(receptive_field), 'rfw: ', np.shape(receptive_field_weight))\n",
    "                        weighted_output = torch.sum(receptive_field * receptive_field_weight, dim=(1,2))\n",
    "                        output_feature_map[k, j, l] = weighted_output[k]\n",
    "            output_feature_maps.append(output_feature_map)\n",
    "        output_feature_maps = torch.stack(output_feature_maps, dim=0)\n",
    "        return output_feature_maps\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        batch_size = grad_output.size(0)\n",
    "        grad_input = torch.zeros((batch_size, self.input_size[0], self.input_size[1], self.filter_size[0], self.filter_size[1]), device=self.weight_matrix.device)\n",
    "        grad_weight = torch.zeros_like(self.weight_matrix)\n",
    "        for i in range(batch_size):\n",
    "            for k in range(self.num_channels):\n",
    "                for j in range(self.output_size[0]):\n",
    "                    for l in range(self.output_size[1]):\n",
    "                        # compute the gradient of the output w.r.t. the receptive field\n",
    "                        grad_weight[k] += grad_output[i, k, j, l] * self.input_feature_map[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]]\n",
    "                        # compute the gradient of the output w.r.t. the input feature map\n",
    "                        grad_input[i, :, j:j+self.filter_size[0], l:l+self.filter_size[1]] += grad_output[i, k, j, l] * self.weight_matrix[k]\n",
    "        self.weight_matrix.grad = torch.sum(grad_weight, dim=0, keepdim=True)\n",
    "        return grad_input\n",
    "    \n",
    "\n",
    "# Define the CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = ConvolutionalLayer(input_size=(16,16), num_channels=16, filter_size=(3, 3))\n",
    "        #self.conv2 = ConvolutionalLayer(input_size=(32,32), num_channels=12, filter_size=(3, 3))\n",
    "        #self.conv3 = ConvolutionalLayer(input_size=(32,32), num_channels=8, filter_size=(3, 3))\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.output_activation = nn.Softmax(dim=1)\n",
    "\n",
    "# leelakrishna's idea\n",
    "    def forward(self, x):\n",
    "        print('Input shape:', x.shape)\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "       # print('Input shape:', x.shape)\n",
    "       # x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "       # print('Input shape:', x.shape)\n",
    "       # x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "       # print('Input shape:', x.shape)\n",
    "        #x = x.view(-1, 64 * 8 * 8)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print('Input shape:', x.shape)\n",
    "        x = nn.functional.relu((x))\n",
    "        #print('Input shape:', x.shape)\n",
    "        #x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aea88ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [1/10], Train Loss: 7.0775, Train Acc: 0.0000, Val Loss: 6.9608, Val Acc: 0.0000\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [2/10], Train Loss: 6.9633, Train Acc: 0.0115, Val Loss: 6.8620, Val Acc: 0.0000\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [3/10], Train Loss: 6.8454, Train Acc: 0.0115, Val Loss: 6.7707, Val Acc: 0.0000\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [4/10], Train Loss: 6.6896, Train Acc: 0.0153, Val Loss: 6.6861, Val Acc: 0.0000\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [5/10], Train Loss: 6.5485, Train Acc: 0.0192, Val Loss: 6.6056, Val Acc: 0.0303\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [6/10], Train Loss: 6.5454, Train Acc: 0.0153, Val Loss: 6.5312, Val Acc: 0.0303\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [7/10], Train Loss: 6.4434, Train Acc: 0.0498, Val Loss: 6.4630, Val Acc: 0.0606\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [8/10], Train Loss: 6.3717, Train Acc: 0.0460, Val Loss: 6.3988, Val Acc: 0.0606\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [9/10], Train Loss: 6.3070, Train Acc: 0.0536, Val Loss: 6.3421, Val Acc: 0.0606\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([1, 32, 32, 3])\n",
      "Input shape: torch.Size([1, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([5, 32, 32, 3])\n",
      "Input shape: torch.Size([5, 784])\n",
      "Input shape: torch.Size([3, 32, 32, 3])\n",
      "Input shape: torch.Size([3, 784])\n",
      "Epoch [10/10], Train Loss: 6.2492, Train Acc: 0.0690, Val Loss: 6.2893, Val Acc: 0.0606\n"
     ]
    }
   ],
   "source": [
    "# Single Layer implementation\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Convert the data to PyTorch tensors and create PyTorch datasets\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(Y_train))\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val), torch.Tensor(Y_val))\n",
    "\n",
    "# Define the batch size for training and validation\n",
    "batch_size = 5 #16\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the model\n",
    "model = CNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_classes=2\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    model.train() # Set the model to training mode\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels = labels.long()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(preds == labels.long())\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = train_acc.float() / len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_acc += torch.sum(preds == labels.long())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_acc.float() / len(val_loader.dataset)\n",
    "\n",
    "    # Print the loss and accuracy for this epoch\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}, Val Loss: {:.4f}, Val Acc: {:.4f}'\n",
    "          .format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba601749",
   "metadata": {},
   "source": [
    "Here, we have build the custom CNN with only one layer. When we tried building it with multiple layers but it was taking very long time to run and the system would crash in between. We have added the code for multiple layers as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29981224",
   "metadata": {},
   "source": [
    "## Anagha's and Leela's Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195661c",
   "metadata": {},
   "source": [
    "## Working on basic CNN to provide visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122dc4df",
   "metadata": {},
   "source": [
    "The basic CNN was implemented using tensorflow and keras. Since it was difficult to show the working of custom CNN model by changing the parameters, we build the basic CNN model using keras and put forth the observations by changing the parameters like learning rate, batch size, optimizers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b17c72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.24.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (58.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.27.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (3.19.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (3.3.7)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (1.50.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard) (2.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from absl-py>=0.4->tensorboard) (1.12.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.1.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\anagh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "# Leelakrishna's idea\n",
    "\n",
    "!pip install tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f01d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9/9 [==============================] - 2s 141ms/step - loss: 0.6926 - accuracy: 0.5632 - val_loss: 0.7081 - val_accuracy: 0.5152\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.6898 - accuracy: 0.5709 - val_loss: 0.7063 - val_accuracy: 0.5152\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.6880 - accuracy: 0.5670 - val_loss: 0.7067 - val_accuracy: 0.5152\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6868 - accuracy: 0.5594 - val_loss: 0.7045 - val_accuracy: 0.5152\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.6855 - accuracy: 0.5594 - val_loss: 0.7057 - val_accuracy: 0.5152\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6847 - accuracy: 0.5709 - val_loss: 0.7043 - val_accuracy: 0.5152\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6835 - accuracy: 0.5632 - val_loss: 0.7047 - val_accuracy: 0.5152\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.6828 - accuracy: 0.5709 - val_loss: 0.7042 - val_accuracy: 0.5152\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.6824 - accuracy: 0.5670 - val_loss: 0.7043 - val_accuracy: 0.5152\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6811 - accuracy: 0.5785 - val_loss: 0.7036 - val_accuracy: 0.5152\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.6805 - accuracy: 0.5785 - val_loss: 0.7041 - val_accuracy: 0.5152\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6798 - accuracy: 0.5747 - val_loss: 0.7025 - val_accuracy: 0.5152\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6790 - accuracy: 0.5824 - val_loss: 0.7022 - val_accuracy: 0.5152\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6772 - accuracy: 0.5709 - val_loss: 0.7024 - val_accuracy: 0.5152\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6767 - accuracy: 0.5747 - val_loss: 0.7041 - val_accuracy: 0.5152\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6758 - accuracy: 0.5747 - val_loss: 0.7036 - val_accuracy: 0.5152\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6754 - accuracy: 0.5709 - val_loss: 0.7035 - val_accuracy: 0.5152\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6725 - accuracy: 0.5747 - val_loss: 0.7028 - val_accuracy: 0.5152\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6722 - accuracy: 0.5747 - val_loss: 0.7020 - val_accuracy: 0.5152\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.6710 - accuracy: 0.5862 - val_loss: 0.7033 - val_accuracy: 0.5152\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.6701 - accuracy: 0.5709 - val_loss: 0.7036 - val_accuracy: 0.5152\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6692 - accuracy: 0.5785 - val_loss: 0.7089 - val_accuracy: 0.5152\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6707 - accuracy: 0.5709 - val_loss: 0.7067 - val_accuracy: 0.5152\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.6664 - accuracy: 0.5709 - val_loss: 0.7060 - val_accuracy: 0.5152\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.6667 - accuracy: 0.5785 - val_loss: 0.7095 - val_accuracy: 0.5152\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.6657 - accuracy: 0.5709 - val_loss: 0.7070 - val_accuracy: 0.5152\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6642 - accuracy: 0.5824 - val_loss: 0.7151 - val_accuracy: 0.5152\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.6644 - accuracy: 0.5709 - val_loss: 0.7018 - val_accuracy: 0.5152\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6633 - accuracy: 0.6130 - val_loss: 0.7034 - val_accuracy: 0.4848\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6602 - accuracy: 0.6092 - val_loss: 0.7043 - val_accuracy: 0.4848\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6573 - accuracy: 0.6935 - val_loss: 0.7191 - val_accuracy: 0.5152\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6603 - accuracy: 0.5709 - val_loss: 0.7094 - val_accuracy: 0.5152\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.6585 - accuracy: 0.5785 - val_loss: 0.7161 - val_accuracy: 0.5152\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6563 - accuracy: 0.5862 - val_loss: 0.7105 - val_accuracy: 0.5152\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6527 - accuracy: 0.5862 - val_loss: 0.7130 - val_accuracy: 0.5152\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.6521 - accuracy: 0.6092 - val_loss: 0.7191 - val_accuracy: 0.5152\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.6519 - accuracy: 0.5824 - val_loss: 0.7058 - val_accuracy: 0.4545\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.6514 - accuracy: 0.6322 - val_loss: 0.7210 - val_accuracy: 0.5152\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.6460 - accuracy: 0.6245 - val_loss: 0.7127 - val_accuracy: 0.4848\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6478 - accuracy: 0.6322 - val_loss: 0.7085 - val_accuracy: 0.4545\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.6458 - accuracy: 0.6705 - val_loss: 0.7091 - val_accuracy: 0.4848\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6441 - accuracy: 0.7011 - val_loss: 0.7252 - val_accuracy: 0.5152\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.6411 - accuracy: 0.5824 - val_loss: 0.7111 - val_accuracy: 0.4545\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6369 - accuracy: 0.6552 - val_loss: 0.7106 - val_accuracy: 0.4242\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.6348 - accuracy: 0.6820 - val_loss: 0.7183 - val_accuracy: 0.4848\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.6323 - accuracy: 0.6590 - val_loss: 0.7102 - val_accuracy: 0.4545\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.6302 - accuracy: 0.7011 - val_loss: 0.7330 - val_accuracy: 0.5152\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.6315 - accuracy: 0.6169 - val_loss: 0.7119 - val_accuracy: 0.4545\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.6239 - accuracy: 0.7011 - val_loss: 0.7138 - val_accuracy: 0.4545\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6187 - accuracy: 0.7165 - val_loss: 0.7313 - val_accuracy: 0.4848\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6255 - accuracy: 0.6322 - val_loss: 0.7655 - val_accuracy: 0.5152\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.6344 - accuracy: 0.6360 - val_loss: 0.7417 - val_accuracy: 0.5152\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6146 - accuracy: 0.6513 - val_loss: 0.7320 - val_accuracy: 0.5152\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.6215 - accuracy: 0.6513 - val_loss: 0.7296 - val_accuracy: 0.4848\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.6168 - accuracy: 0.7165 - val_loss: 0.7704 - val_accuracy: 0.5152\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.6214 - accuracy: 0.6437 - val_loss: 0.7223 - val_accuracy: 0.5152\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6058 - accuracy: 0.7050 - val_loss: 0.7189 - val_accuracy: 0.5152\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6095 - accuracy: 0.6667 - val_loss: 0.7415 - val_accuracy: 0.4848\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 59ms/step - loss: 0.6115 - accuracy: 0.6284 - val_loss: 0.7312 - val_accuracy: 0.4848\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.6022 - accuracy: 0.6782 - val_loss: 0.7324 - val_accuracy: 0.4848\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5981 - accuracy: 0.6897 - val_loss: 0.7690 - val_accuracy: 0.5152\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.6040 - accuracy: 0.6858 - val_loss: 0.7610 - val_accuracy: 0.5152\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.5946 - accuracy: 0.6782 - val_loss: 0.7343 - val_accuracy: 0.5152\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.5919 - accuracy: 0.7050 - val_loss: 0.7322 - val_accuracy: 0.4848\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.6047 - accuracy: 0.6667 - val_loss: 0.9369 - val_accuracy: 0.4848\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.6609 - accuracy: 0.6130 - val_loss: 0.7478 - val_accuracy: 0.4848\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.6025 - accuracy: 0.6475 - val_loss: 0.8148 - val_accuracy: 0.5152\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.6080 - accuracy: 0.6858 - val_loss: 0.7404 - val_accuracy: 0.5152\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5960 - accuracy: 0.6820 - val_loss: 0.7715 - val_accuracy: 0.5455\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.5989 - accuracy: 0.6897 - val_loss: 0.7188 - val_accuracy: 0.5455\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5787 - accuracy: 0.7433 - val_loss: 0.7156 - val_accuracy: 0.4545\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5788 - accuracy: 0.7050 - val_loss: 0.7321 - val_accuracy: 0.5455\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5954 - accuracy: 0.6705 - val_loss: 0.7234 - val_accuracy: 0.4545\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.5732 - accuracy: 0.6973 - val_loss: 0.7351 - val_accuracy: 0.5152\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5758 - accuracy: 0.6743 - val_loss: 0.7367 - val_accuracy: 0.4848\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5671 - accuracy: 0.7126 - val_loss: 0.7364 - val_accuracy: 0.4242\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5671 - accuracy: 0.7241 - val_loss: 0.7637 - val_accuracy: 0.5152\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.5654 - accuracy: 0.7395 - val_loss: 0.7574 - val_accuracy: 0.5152\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5524 - accuracy: 0.6973 - val_loss: 0.7686 - val_accuracy: 0.5152\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.5604 - accuracy: 0.6858 - val_loss: 0.7298 - val_accuracy: 0.3939\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5541 - accuracy: 0.7318 - val_loss: 0.7373 - val_accuracy: 0.4545\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5507 - accuracy: 0.7395 - val_loss: 0.7894 - val_accuracy: 0.4848\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.5531 - accuracy: 0.7011 - val_loss: 0.7389 - val_accuracy: 0.5152\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5584 - accuracy: 0.7050 - val_loss: 0.8132 - val_accuracy: 0.5455\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.5690 - accuracy: 0.7011 - val_loss: 0.7759 - val_accuracy: 0.5152\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5501 - accuracy: 0.7050 - val_loss: 0.7741 - val_accuracy: 0.5758\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5472 - accuracy: 0.7280 - val_loss: 0.7908 - val_accuracy: 0.5152\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5501 - accuracy: 0.7510 - val_loss: 0.8367 - val_accuracy: 0.5152\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5568 - accuracy: 0.7165 - val_loss: 0.9100 - val_accuracy: 0.5152\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5698 - accuracy: 0.7050 - val_loss: 0.7515 - val_accuracy: 0.5455\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.5350 - accuracy: 0.7510 - val_loss: 0.7515 - val_accuracy: 0.4848\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5383 - accuracy: 0.7395 - val_loss: 0.7508 - val_accuracy: 0.4242\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.5346 - accuracy: 0.7356 - val_loss: 0.7997 - val_accuracy: 0.5455\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5304 - accuracy: 0.7318 - val_loss: 0.7635 - val_accuracy: 0.4848\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5319 - accuracy: 0.7126 - val_loss: 0.7815 - val_accuracy: 0.6061\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5361 - accuracy: 0.7356 - val_loss: 0.7924 - val_accuracy: 0.5152\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.5181 - accuracy: 0.7471 - val_loss: 0.8861 - val_accuracy: 0.4848\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.5565 - accuracy: 0.7241 - val_loss: 0.7533 - val_accuracy: 0.4242\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.5120 - accuracy: 0.7739 - val_loss: 0.7612 - val_accuracy: 0.4545\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.5230 - accuracy: 0.7318 - val_loss: 0.7629 - val_accuracy: 0.4242\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.5030 - accuracy: 0.7778 - val_loss: 0.7965 - val_accuracy: 0.4242\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.5243 - accuracy: 0.7280 - val_loss: 1.0131 - val_accuracy: 0.5152\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.5575 - accuracy: 0.7088 - val_loss: 0.7406 - val_accuracy: 0.4545\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.5052 - accuracy: 0.7816 - val_loss: 0.8176 - val_accuracy: 0.5152\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.5183 - accuracy: 0.7433 - val_loss: 0.7534 - val_accuracy: 0.4545\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.4955 - accuracy: 0.7701 - val_loss: 0.7822 - val_accuracy: 0.4848\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.5007 - accuracy: 0.7548 - val_loss: 0.8770 - val_accuracy: 0.5455\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.5193 - accuracy: 0.7433 - val_loss: 0.8093 - val_accuracy: 0.5152\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5171 - accuracy: 0.7356 - val_loss: 0.7561 - val_accuracy: 0.3939\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.4881 - accuracy: 0.7739 - val_loss: 0.7770 - val_accuracy: 0.4242\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5029 - accuracy: 0.7816 - val_loss: 0.8139 - val_accuracy: 0.5152\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.5066 - accuracy: 0.7395 - val_loss: 0.7863 - val_accuracy: 0.4242\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5197 - accuracy: 0.7356 - val_loss: 0.7927 - val_accuracy: 0.5152\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.5005 - accuracy: 0.7586 - val_loss: 0.7716 - val_accuracy: 0.4848\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4821 - accuracy: 0.7739 - val_loss: 0.7647 - val_accuracy: 0.3939\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4814 - accuracy: 0.7969 - val_loss: 0.7843 - val_accuracy: 0.4242\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 57ms/step - loss: 0.4788 - accuracy: 0.8046 - val_loss: 0.8842 - val_accuracy: 0.6061\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4819 - accuracy: 0.7663 - val_loss: 0.8252 - val_accuracy: 0.4242\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4748 - accuracy: 0.7625 - val_loss: 0.8038 - val_accuracy: 0.4848\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.4913 - accuracy: 0.7471 - val_loss: 0.8044 - val_accuracy: 0.4545\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4789 - accuracy: 0.7701 - val_loss: 0.8339 - val_accuracy: 0.5758\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4737 - accuracy: 0.7586 - val_loss: 0.7752 - val_accuracy: 0.3939\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4674 - accuracy: 0.7893 - val_loss: 0.7932 - val_accuracy: 0.3939\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4687 - accuracy: 0.7586 - val_loss: 1.0007 - val_accuracy: 0.5455\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.5063 - accuracy: 0.7625 - val_loss: 0.8073 - val_accuracy: 0.4848\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.4685 - accuracy: 0.7893 - val_loss: 0.9561 - val_accuracy: 0.5455\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.5001 - accuracy: 0.7356 - val_loss: 0.7740 - val_accuracy: 0.3939\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.4735 - accuracy: 0.7663 - val_loss: 1.0330 - val_accuracy: 0.5152\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.5356 - accuracy: 0.7241 - val_loss: 0.7599 - val_accuracy: 0.4242\n",
      "Epoch 130/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4772 - accuracy: 0.7701 - val_loss: 0.7843 - val_accuracy: 0.4545\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.4670 - accuracy: 0.7663 - val_loss: 0.7968 - val_accuracy: 0.4848\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.7838 - val_accuracy: 0.4242\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.4744 - accuracy: 0.7854 - val_loss: 0.8837 - val_accuracy: 0.5758\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.8819 - val_accuracy: 0.5152\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.4493 - accuracy: 0.7931 - val_loss: 0.9084 - val_accuracy: 0.6061\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4627 - accuracy: 0.7931 - val_loss: 0.8237 - val_accuracy: 0.5152\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4386 - accuracy: 0.8046 - val_loss: 0.8071 - val_accuracy: 0.4545\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4434 - accuracy: 0.8046 - val_loss: 0.8940 - val_accuracy: 0.4848\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.4590 - accuracy: 0.8008 - val_loss: 0.8023 - val_accuracy: 0.4242\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4354 - accuracy: 0.8084 - val_loss: 0.8091 - val_accuracy: 0.4242\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4557 - accuracy: 0.7854 - val_loss: 0.9864 - val_accuracy: 0.5758\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4855 - accuracy: 0.7816 - val_loss: 0.8684 - val_accuracy: 0.4848\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4372 - accuracy: 0.8238 - val_loss: 0.9257 - val_accuracy: 0.5758\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.4622 - accuracy: 0.7969 - val_loss: 0.8332 - val_accuracy: 0.5455\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.4354 - accuracy: 0.8084 - val_loss: 0.8960 - val_accuracy: 0.6061\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4258 - accuracy: 0.8199 - val_loss: 0.8381 - val_accuracy: 0.4848\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.4293 - accuracy: 0.8199 - val_loss: 0.9659 - val_accuracy: 0.6061\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.4415 - accuracy: 0.7931 - val_loss: 0.8351 - val_accuracy: 0.3939\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4243 - accuracy: 0.8314 - val_loss: 0.8388 - val_accuracy: 0.5152\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.4239 - accuracy: 0.8314 - val_loss: 0.8453 - val_accuracy: 0.4848\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.4284 - accuracy: 0.8161 - val_loss: 0.8243 - val_accuracy: 0.3939\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.4212 - accuracy: 0.7931 - val_loss: 1.2840 - val_accuracy: 0.5152\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4844 - accuracy: 0.7893 - val_loss: 0.8102 - val_accuracy: 0.3939\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.4139 - accuracy: 0.8238 - val_loss: 0.8276 - val_accuracy: 0.5152\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.4166 - accuracy: 0.8084 - val_loss: 0.7525 - val_accuracy: 0.4848\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.4140 - accuracy: 0.8314 - val_loss: 0.8188 - val_accuracy: 0.3939\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3976 - accuracy: 0.8467 - val_loss: 0.8445 - val_accuracy: 0.3939\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.3998 - accuracy: 0.8276 - val_loss: 0.8292 - val_accuracy: 0.4242\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4066 - accuracy: 0.8314 - val_loss: 0.9396 - val_accuracy: 0.5758\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4032 - accuracy: 0.8352 - val_loss: 0.8364 - val_accuracy: 0.4848\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3929 - accuracy: 0.8506 - val_loss: 0.8853 - val_accuracy: 0.5455\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.3900 - accuracy: 0.8084 - val_loss: 0.9979 - val_accuracy: 0.6061\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3897 - accuracy: 0.8238 - val_loss: 0.9403 - val_accuracy: 0.5758\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.4017 - accuracy: 0.8238 - val_loss: 1.1008 - val_accuracy: 0.5758\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.4064 - accuracy: 0.8238 - val_loss: 0.8263 - val_accuracy: 0.4545\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.3828 - accuracy: 0.8467 - val_loss: 0.8636 - val_accuracy: 0.4545\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.3718 - accuracy: 0.8352 - val_loss: 1.2049 - val_accuracy: 0.5758\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.4192 - accuracy: 0.8161 - val_loss: 1.0991 - val_accuracy: 0.5758\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.3911 - accuracy: 0.8544 - val_loss: 0.9414 - val_accuracy: 0.5758\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3884 - accuracy: 0.8314 - val_loss: 0.9517 - val_accuracy: 0.5758\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3808 - accuracy: 0.8582 - val_loss: 0.8692 - val_accuracy: 0.4242\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3671 - accuracy: 0.8506 - val_loss: 0.8521 - val_accuracy: 0.4242\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3677 - accuracy: 0.8582 - val_loss: 0.8383 - val_accuracy: 0.3939\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3733 - accuracy: 0.8621 - val_loss: 0.8508 - val_accuracy: 0.4848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.3471 - accuracy: 0.8582 - val_loss: 0.9374 - val_accuracy: 0.5455\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3569 - accuracy: 0.8774 - val_loss: 1.1419 - val_accuracy: 0.5455\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.4006 - accuracy: 0.8429 - val_loss: 1.1717 - val_accuracy: 0.6061\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.3887 - accuracy: 0.8467 - val_loss: 0.8348 - val_accuracy: 0.3939\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.3521 - accuracy: 0.8621 - val_loss: 0.9725 - val_accuracy: 0.5455\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3601 - accuracy: 0.8582 - val_loss: 1.3449 - val_accuracy: 0.5152\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.4714 - accuracy: 0.7816 - val_loss: 0.8258 - val_accuracy: 0.4242\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3511 - accuracy: 0.8621 - val_loss: 0.8529 - val_accuracy: 0.4242\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.3455 - accuracy: 0.8774 - val_loss: 1.2401 - val_accuracy: 0.5758\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.3749 - accuracy: 0.8429 - val_loss: 0.8239 - val_accuracy: 0.3939\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3388 - accuracy: 0.8697 - val_loss: 0.8998 - val_accuracy: 0.4848\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3507 - accuracy: 0.8467 - val_loss: 0.8172 - val_accuracy: 0.4848\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3320 - accuracy: 0.8851 - val_loss: 0.7908 - val_accuracy: 0.5152\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3316 - accuracy: 0.8889 - val_loss: 0.9033 - val_accuracy: 0.4545\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3247 - accuracy: 0.8851 - val_loss: 0.8777 - val_accuracy: 0.5455\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.3279 - accuracy: 0.8774 - val_loss: 0.8206 - val_accuracy: 0.4545\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3205 - accuracy: 0.8851 - val_loss: 0.9528 - val_accuracy: 0.5758\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3166 - accuracy: 0.8812 - val_loss: 0.8995 - val_accuracy: 0.5152\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.3121 - accuracy: 0.8851 - val_loss: 0.8396 - val_accuracy: 0.4848\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.3444 - accuracy: 0.8391 - val_loss: 0.8200 - val_accuracy: 0.4848\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.3168 - accuracy: 0.9004 - val_loss: 0.8350 - val_accuracy: 0.4242\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.2976 - accuracy: 0.9157 - val_loss: 0.9254 - val_accuracy: 0.5758\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.3071 - accuracy: 0.8927 - val_loss: 0.8561 - val_accuracy: 0.4848\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.2897 - accuracy: 0.9042 - val_loss: 0.9844 - val_accuracy: 0.5455\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3035 - accuracy: 0.8851 - val_loss: 0.9346 - val_accuracy: 0.5455\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2971 - accuracy: 0.8774 - val_loss: 1.0049 - val_accuracy: 0.5152\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.2988 - accuracy: 0.8659 - val_loss: 1.0524 - val_accuracy: 0.5758\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.2880 - accuracy: 0.9004 - val_loss: 1.0422 - val_accuracy: 0.5152\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2859 - accuracy: 0.8889 - val_loss: 0.9397 - val_accuracy: 0.5152\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2855 - accuracy: 0.9080 - val_loss: 0.8825 - val_accuracy: 0.3939\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2833 - accuracy: 0.8812 - val_loss: 0.9863 - val_accuracy: 0.4545\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.2754 - accuracy: 0.9080 - val_loss: 0.9148 - val_accuracy: 0.4242\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2615 - accuracy: 0.9272 - val_loss: 1.4087 - val_accuracy: 0.5152\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3394 - accuracy: 0.8774 - val_loss: 1.0976 - val_accuracy: 0.5758\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.2768 - accuracy: 0.8774 - val_loss: 0.8944 - val_accuracy: 0.4242\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.2682 - accuracy: 0.9119 - val_loss: 1.1250 - val_accuracy: 0.5758\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.2858 - accuracy: 0.9080 - val_loss: 0.9157 - val_accuracy: 0.3939\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.2517 - accuracy: 0.9157 - val_loss: 0.9767 - val_accuracy: 0.5152\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.2813 - accuracy: 0.9080 - val_loss: 0.9001 - val_accuracy: 0.5152\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2501 - accuracy: 0.9310 - val_loss: 0.9250 - val_accuracy: 0.4242\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2412 - accuracy: 0.9425 - val_loss: 0.9358 - val_accuracy: 0.4242\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.2482 - accuracy: 0.9195 - val_loss: 0.9535 - val_accuracy: 0.4545\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2359 - accuracy: 0.9349 - val_loss: 0.9928 - val_accuracy: 0.4545\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.2429 - accuracy: 0.9310 - val_loss: 0.9310 - val_accuracy: 0.3939\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.2402 - accuracy: 0.9157 - val_loss: 0.9351 - val_accuracy: 0.4545\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.2268 - accuracy: 0.9272 - val_loss: 0.9634 - val_accuracy: 0.5758\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.2301 - accuracy: 0.9234 - val_loss: 0.9350 - val_accuracy: 0.5152\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.2739 - accuracy: 0.8812 - val_loss: 1.1571 - val_accuracy: 0.5758\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.2588 - accuracy: 0.8927 - val_loss: 0.9574 - val_accuracy: 0.4242\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.2313 - accuracy: 0.9195 - val_loss: 0.9385 - val_accuracy: 0.4848\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.2197 - accuracy: 0.9272 - val_loss: 1.0605 - val_accuracy: 0.5455\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.2135 - accuracy: 0.9425 - val_loss: 1.0521 - val_accuracy: 0.5455\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.2072 - accuracy: 0.9425 - val_loss: 1.0081 - val_accuracy: 0.4848\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.2054 - accuracy: 0.9349 - val_loss: 0.9353 - val_accuracy: 0.5152\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.2095 - accuracy: 0.9310 - val_loss: 0.9581 - val_accuracy: 0.4242\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.1997 - accuracy: 0.9579 - val_loss: 1.0341 - val_accuracy: 0.4545\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1866 - accuracy: 0.9693 - val_loss: 1.2004 - val_accuracy: 0.4545\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.1951 - accuracy: 0.9579 - val_loss: 1.0313 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/500\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.1958 - accuracy: 0.9655 - val_loss: 1.0098 - val_accuracy: 0.4545\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.1877 - accuracy: 0.9502 - val_loss: 1.1544 - val_accuracy: 0.4242\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2518 - accuracy: 0.8889 - val_loss: 1.1115 - val_accuracy: 0.4848\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.1849 - accuracy: 0.9770 - val_loss: 1.0335 - val_accuracy: 0.4848\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1718 - accuracy: 0.9579 - val_loss: 1.0363 - val_accuracy: 0.4848\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.1662 - accuracy: 0.9693 - val_loss: 1.1100 - val_accuracy: 0.4545\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.1697 - accuracy: 0.9655 - val_loss: 1.0066 - val_accuracy: 0.4242\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.1635 - accuracy: 0.9655 - val_loss: 1.0765 - val_accuracy: 0.5758\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.1575 - accuracy: 0.9693 - val_loss: 1.0344 - val_accuracy: 0.4848\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.1709 - accuracy: 0.9617 - val_loss: 1.1724 - val_accuracy: 0.4545\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.1551 - accuracy: 0.9693 - val_loss: 1.4106 - val_accuracy: 0.5758\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.2095 - accuracy: 0.9310 - val_loss: 1.1154 - val_accuracy: 0.4545\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.1791 - accuracy: 0.9579 - val_loss: 1.2300 - val_accuracy: 0.5152\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1563 - accuracy: 0.9693 - val_loss: 1.1924 - val_accuracy: 0.5455\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.1552 - accuracy: 0.9732 - val_loss: 1.1874 - val_accuracy: 0.5758\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.1397 - accuracy: 0.9732 - val_loss: 1.0987 - val_accuracy: 0.5152\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1499 - accuracy: 0.9617 - val_loss: 1.1272 - val_accuracy: 0.4242\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.1333 - accuracy: 0.9808 - val_loss: 1.1161 - val_accuracy: 0.5455\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.1340 - accuracy: 0.9770 - val_loss: 1.0865 - val_accuracy: 0.4545\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1315 - accuracy: 0.9732 - val_loss: 1.2667 - val_accuracy: 0.5152\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.1543 - accuracy: 0.9617 - val_loss: 1.1552 - val_accuracy: 0.4545\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.1168 - accuracy: 0.9923 - val_loss: 1.1952 - val_accuracy: 0.4545\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.1170 - accuracy: 0.9923 - val_loss: 1.1369 - val_accuracy: 0.4545\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.1113 - accuracy: 0.9962 - val_loss: 1.2405 - val_accuracy: 0.4242\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1160 - accuracy: 0.9847 - val_loss: 1.1894 - val_accuracy: 0.5455\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1153 - accuracy: 0.9885 - val_loss: 1.2308 - val_accuracy: 0.4848\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 1s 63ms/step - loss: 0.1190 - accuracy: 0.9847 - val_loss: 1.7950 - val_accuracy: 0.5152\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1558 - accuracy: 0.9464 - val_loss: 1.1930 - val_accuracy: 0.4848\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1222 - accuracy: 0.9808 - val_loss: 1.2660 - val_accuracy: 0.4242\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1003 - accuracy: 0.9962 - val_loss: 1.1426 - val_accuracy: 0.4848\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1044 - accuracy: 0.9923 - val_loss: 1.2574 - val_accuracy: 0.4848\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0972 - accuracy: 0.9962 - val_loss: 1.1903 - val_accuracy: 0.4848\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0947 - accuracy: 0.9923 - val_loss: 1.3752 - val_accuracy: 0.4242\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0979 - accuracy: 0.9847 - val_loss: 1.2262 - val_accuracy: 0.4848\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0862 - accuracy: 0.9923 - val_loss: 1.3126 - val_accuracy: 0.5455\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0986 - accuracy: 0.9847 - val_loss: 1.2996 - val_accuracy: 0.4545\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0857 - accuracy: 0.9962 - val_loss: 1.2952 - val_accuracy: 0.4848\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0795 - accuracy: 0.9962 - val_loss: 1.3066 - val_accuracy: 0.5152\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0857 - accuracy: 0.9962 - val_loss: 1.4943 - val_accuracy: 0.3939\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0817 - accuracy: 0.9923 - val_loss: 1.3815 - val_accuracy: 0.5455\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0767 - accuracy: 0.9923 - val_loss: 1.3021 - val_accuracy: 0.4545\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 0.0782 - accuracy: 0.9962 - val_loss: 1.2999 - val_accuracy: 0.4848\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0704 - accuracy: 0.9962 - val_loss: 1.7888 - val_accuracy: 0.4545\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.1678 - accuracy: 0.9387 - val_loss: 1.2936 - val_accuracy: 0.5152\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0686 - accuracy: 0.9962 - val_loss: 1.4130 - val_accuracy: 0.4848\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0867 - accuracy: 0.9923 - val_loss: 1.5850 - val_accuracy: 0.4242\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0796 - accuracy: 0.9923 - val_loss: 1.4492 - val_accuracy: 0.4242\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0669 - accuracy: 0.9962 - val_loss: 1.4997 - val_accuracy: 0.4242\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0708 - accuracy: 0.9962 - val_loss: 1.3384 - val_accuracy: 0.5152\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0611 - accuracy: 0.9962 - val_loss: 1.4079 - val_accuracy: 0.5455\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0638 - accuracy: 0.9962 - val_loss: 1.4393 - val_accuracy: 0.4545\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0566 - accuracy: 0.9962 - val_loss: 1.4366 - val_accuracy: 0.4242\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 1.5846 - val_accuracy: 0.3939\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0652 - accuracy: 0.9962 - val_loss: 1.4709 - val_accuracy: 0.4848\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0600 - accuracy: 0.9962 - val_loss: 1.7035 - val_accuracy: 0.4242\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0596 - accuracy: 0.9923 - val_loss: 1.4340 - val_accuracy: 0.5152\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.5177 - val_accuracy: 0.5455\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 1.5020 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.4925 - val_accuracy: 0.5152\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 1.6066 - val_accuracy: 0.5152\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.3811 - val_accuracy: 0.5152\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 1.5567 - val_accuracy: 0.4545\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0462 - accuracy: 0.9962 - val_loss: 1.5326 - val_accuracy: 0.5152\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 1.5155 - val_accuracy: 0.4848\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 1.5539 - val_accuracy: 0.4848\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 1.5589 - val_accuracy: 0.5455\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 1s 64ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 1.6090 - val_accuracy: 0.4545\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.6323 - val_accuracy: 0.4242\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 1.6021 - val_accuracy: 0.4848\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 1.5860 - val_accuracy: 0.5455\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.6254 - val_accuracy: 0.5152\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.6274 - val_accuracy: 0.5455\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 1.7290 - val_accuracy: 0.4242\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.6030 - val_accuracy: 0.5152\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.6273 - val_accuracy: 0.5152\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.6709 - val_accuracy: 0.4848\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.6380 - val_accuracy: 0.5152\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.4848\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.6255 - val_accuracy: 0.5455\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.6597 - val_accuracy: 0.5455\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.6254 - val_accuracy: 0.5152\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 1.6289 - val_accuracy: 0.5152\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.6804 - val_accuracy: 0.5152\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.6768 - val_accuracy: 0.4848\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.6649 - val_accuracy: 0.5455\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.7432 - val_accuracy: 0.5152\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.7193 - val_accuracy: 0.5152\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.7109 - val_accuracy: 0.4848\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.7381 - val_accuracy: 0.5152\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.6958 - val_accuracy: 0.5152\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.7566 - val_accuracy: 0.5152\n",
      "Epoch 324/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.7409 - val_accuracy: 0.5152\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 60ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.7758 - val_accuracy: 0.5152\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.8116 - val_accuracy: 0.4848\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.7749 - val_accuracy: 0.4848\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.8321 - val_accuracy: 0.4848\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.7749 - val_accuracy: 0.5152\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.7485 - val_accuracy: 0.5152\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.7526 - val_accuracy: 0.5152\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.7908 - val_accuracy: 0.4848\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.8033 - val_accuracy: 0.5455\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.8577 - val_accuracy: 0.5152\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.8258 - val_accuracy: 0.4545\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.8808 - val_accuracy: 0.4848\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.8495 - val_accuracy: 0.4848\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.0227 - val_accuracy: 0.4242\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.8285 - val_accuracy: 0.5152\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.9336 - val_accuracy: 0.5455\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.8480 - val_accuracy: 0.5152\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.8433 - val_accuracy: 0.5152\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.8547 - val_accuracy: 0.5455\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.9406 - val_accuracy: 0.5152\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.9418 - val_accuracy: 0.5152\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.9040 - val_accuracy: 0.4545\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.5455\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.9358 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.9090 - val_accuracy: 0.5152\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.9018 - val_accuracy: 0.5152\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 2.1192 - val_accuracy: 0.3939\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.0861 - val_accuracy: 0.4545\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.9116 - val_accuracy: 0.5455\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.9598 - val_accuracy: 0.5152\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 0.5152\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 0.5152\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.9391 - val_accuracy: 0.5152\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.9155 - val_accuracy: 0.5152\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.9425 - val_accuracy: 0.5152\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.9299 - val_accuracy: 0.5455\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.0012 - val_accuracy: 0.5455\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.9458 - val_accuracy: 0.5152\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.0222 - val_accuracy: 0.5455\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.0077 - val_accuracy: 0.5152\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.0079 - val_accuracy: 0.5152\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.9680 - val_accuracy: 0.5455\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 1s 62ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.0172 - val_accuracy: 0.5152\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.0317 - val_accuracy: 0.4848\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 2.0055 - val_accuracy: 0.4848\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.1050 - val_accuracy: 0.5152\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 2.0410 - val_accuracy: 0.4545\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.0301 - val_accuracy: 0.5152\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.0479 - val_accuracy: 0.5455\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.1175 - val_accuracy: 0.5152\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.0440 - val_accuracy: 0.5152\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.0674 - val_accuracy: 0.5152\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.0647 - val_accuracy: 0.5152\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.0834 - val_accuracy: 0.4848\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.0359 - val_accuracy: 0.5152\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.0065 - val_accuracy: 0.5455\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.0722 - val_accuracy: 0.5152\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.0728 - val_accuracy: 0.5152\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.0879 - val_accuracy: 0.4848\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.0868 - val_accuracy: 0.4848\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.0673 - val_accuracy: 0.5152\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.1026 - val_accuracy: 0.5152\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 2.1060 - val_accuracy: 0.5455\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.0907 - val_accuracy: 0.5152\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.1188 - val_accuracy: 0.5152\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 59ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.1076 - val_accuracy: 0.5152\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.1105 - val_accuracy: 0.5152\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.1271 - val_accuracy: 0.4848\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.2064 - val_accuracy: 0.5152\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.1463 - val_accuracy: 0.5152\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.2008 - val_accuracy: 0.5152\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1469 - val_accuracy: 0.4848\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.2070 - val_accuracy: 0.5152\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1311 - val_accuracy: 0.5455\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.1705 - val_accuracy: 0.4848\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1607 - val_accuracy: 0.4848\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.1643 - val_accuracy: 0.5455\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1448 - val_accuracy: 0.5152\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.1649 - val_accuracy: 0.4848\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.2103 - val_accuracy: 0.5152\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.1971 - val_accuracy: 0.4848\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.1329 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.1851 - val_accuracy: 0.5152\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.1857 - val_accuracy: 0.5455\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.2097 - val_accuracy: 0.5455\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.2033 - val_accuracy: 0.4848\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.2109 - val_accuracy: 0.4848\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.2232 - val_accuracy: 0.4545\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.2500 - val_accuracy: 0.5152\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1945 - val_accuracy: 0.5152\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.2150 - val_accuracy: 0.5455\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.2139 - val_accuracy: 0.5455\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.2091 - val_accuracy: 0.4848\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.2324 - val_accuracy: 0.5152\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.2569 - val_accuracy: 0.4848\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2350 - val_accuracy: 0.5152\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2326 - val_accuracy: 0.5455\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.2731 - val_accuracy: 0.5152\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.2634 - val_accuracy: 0.5152\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.2620 - val_accuracy: 0.5455\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.2835 - val_accuracy: 0.5152\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 58ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.2734 - val_accuracy: 0.4848\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.3106 - val_accuracy: 0.5152\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.2666 - val_accuracy: 0.4848\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.2752 - val_accuracy: 0.4848\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.5152\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.2697 - val_accuracy: 0.5455\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2749 - val_accuracy: 0.4848\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.2996 - val_accuracy: 0.4848\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.2971 - val_accuracy: 0.5152\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.4848\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.2679 - val_accuracy: 0.5152\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2749 - val_accuracy: 0.5152\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.2897 - val_accuracy: 0.5455\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.2703 - val_accuracy: 0.5455\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.2688 - val_accuracy: 0.5152\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.2771 - val_accuracy: 0.5152\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.3496 - val_accuracy: 0.5455\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.3157 - val_accuracy: 0.5152\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.3010 - val_accuracy: 0.5455\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.2980 - val_accuracy: 0.5152\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.3377 - val_accuracy: 0.5152\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.3092 - val_accuracy: 0.5152\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.3118 - val_accuracy: 0.5455\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.3209 - val_accuracy: 0.5455\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.3145 - val_accuracy: 0.5455\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.3217 - val_accuracy: 0.5455\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.3323 - val_accuracy: 0.5455\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.3406 - val_accuracy: 0.5455\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.3369 - val_accuracy: 0.5455\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.3397 - val_accuracy: 0.5455\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.3485 - val_accuracy: 0.5455\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.3488 - val_accuracy: 0.4848\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.3379 - val_accuracy: 0.4848\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.3843 - val_accuracy: 0.5152\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.3693 - val_accuracy: 0.4848\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.3711 - val_accuracy: 0.5152\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 1s 65ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.4035 - val_accuracy: 0.5152\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.3837 - val_accuracy: 0.4848\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3756 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3638 - val_accuracy: 0.5152\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.4013 - val_accuracy: 0.5152\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3911 - val_accuracy: 0.4848\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3703 - val_accuracy: 0.5152\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3852 - val_accuracy: 0.5152\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3874 - val_accuracy: 0.5152\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3784 - val_accuracy: 0.5455\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3986 - val_accuracy: 0.4848\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3925 - val_accuracy: 0.5152\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.4209 - val_accuracy: 0.5152\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.4122 - val_accuracy: 0.5152\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 51ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3912 - val_accuracy: 0.5152\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3787 - val_accuracy: 0.5152\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3954 - val_accuracy: 0.5455\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.4128 - val_accuracy: 0.5152\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4221 - val_accuracy: 0.4848\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4020 - val_accuracy: 0.5152\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4032 - val_accuracy: 0.5152\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4051 - val_accuracy: 0.5152\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.4135 - val_accuracy: 0.5758\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4242 - val_accuracy: 0.5152\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.4215 - val_accuracy: 0.4848\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4373 - val_accuracy: 0.4848\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.4287 - val_accuracy: 0.5152\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4371 - val_accuracy: 0.5152\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4213 - val_accuracy: 0.5455\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4327 - val_accuracy: 0.5152\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4305 - val_accuracy: 0.5455\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4508 - val_accuracy: 0.5152\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.4476 - val_accuracy: 0.4848\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4443 - val_accuracy: 0.5455\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.4848\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4520 - val_accuracy: 0.4848\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4678 - val_accuracy: 0.5152\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4547 - val_accuracy: 0.5152\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4578 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9151 - accuracy: 0.6061\n",
      "Test accuracy: 0.6060606241226196\n"
     ]
    }
   ],
   "source": [
    "# Leela's Implementation\n",
    "import datetime\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(12, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2)  # Use 2 output units for binary classification\n",
    "])\n",
    "\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "\n",
    "# Step 3: Train and evaluate model\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history1 = model.fit(X_train, Y_train, epochs=500, batch_size=32, \n",
    "                    validation_data=(X_val, Y_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99101a9",
   "metadata": {},
   "source": [
    "# Implementation of the layer and complete model with a figure in tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21dfae56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fbf8185ac0807a05\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fbf8185ac0807a05\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e780d0",
   "metadata": {},
   "source": [
    "Also we have implemented the tensor board which allows us to monitor and visualize loss function, accuracy and other performance metrics.\n",
    "\n",
    "We can also visualize the structure of our model’s graph and explore its parameters. We can also debug our model by visualizing the gradients and activations and weights of our model’s layers.\n",
    "\n",
    "It is a user friendly interface which has helped us to optimize our models performance and improve its accuracy.\n",
    "\n",
    "Because we were finding it was taking too long with our custom model we showed the tensorboard implementation with our basic CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed82393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "6/6 [==============================] - 1s 67ms/step - loss: 0.3371 - accuracy: 0.5517 - val_loss: 0.3098 - val_accuracy: 0.6061\n",
      "Epoch 2/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2570 - accuracy: 0.4253 - val_loss: 0.3060 - val_accuracy: 0.5758\n",
      "Epoch 3/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2385 - accuracy: 0.4559 - val_loss: 0.2988 - val_accuracy: 0.6061\n",
      "Epoch 4/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2267 - accuracy: 0.4483 - val_loss: 0.3011 - val_accuracy: 0.6061\n",
      "Epoch 5/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2155 - accuracy: 0.4291 - val_loss: 0.2997 - val_accuracy: 0.5455\n",
      "Epoch 6/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2130 - accuracy: 0.4483 - val_loss: 0.2992 - val_accuracy: 0.6061\n",
      "Epoch 7/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1968 - accuracy: 0.4330 - val_loss: 0.2984 - val_accuracy: 0.5455\n",
      "Epoch 8/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1886 - accuracy: 0.4330 - val_loss: 0.2909 - val_accuracy: 0.6061\n",
      "Epoch 9/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1777 - accuracy: 0.3985 - val_loss: 0.2919 - val_accuracy: 0.5152\n",
      "Epoch 10/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1709 - accuracy: 0.4061 - val_loss: 0.2942 - val_accuracy: 0.6364\n",
      "Epoch 11/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1660 - accuracy: 0.3602 - val_loss: 0.2987 - val_accuracy: 0.5152\n",
      "Epoch 12/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1538 - accuracy: 0.3793 - val_loss: 0.2949 - val_accuracy: 0.6364\n",
      "Epoch 13/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1476 - accuracy: 0.3372 - val_loss: 0.3003 - val_accuracy: 0.6061\n",
      "Epoch 14/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1388 - accuracy: 0.2989 - val_loss: 0.3013 - val_accuracy: 0.5758\n",
      "Epoch 15/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1328 - accuracy: 0.3180 - val_loss: 0.3014 - val_accuracy: 0.6061\n",
      "Epoch 16/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1259 - accuracy: 0.3027 - val_loss: 0.3116 - val_accuracy: 0.5758\n",
      "Epoch 17/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1278 - accuracy: 0.3295 - val_loss: 0.3015 - val_accuracy: 0.6061\n",
      "Epoch 18/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1130 - accuracy: 0.3103 - val_loss: 0.2987 - val_accuracy: 0.5455\n",
      "Epoch 19/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1086 - accuracy: 0.3180 - val_loss: 0.3002 - val_accuracy: 0.6667\n",
      "Epoch 20/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1010 - accuracy: 0.2720 - val_loss: 0.3015 - val_accuracy: 0.5152\n",
      "Epoch 21/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0996 - accuracy: 0.2605 - val_loss: 0.2966 - val_accuracy: 0.5455\n",
      "Epoch 22/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0911 - accuracy: 0.2605 - val_loss: 0.2936 - val_accuracy: 0.6667\n",
      "Epoch 23/400\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0863 - accuracy: 0.2299 - val_loss: 0.2911 - val_accuracy: 0.6667\n",
      "Epoch 24/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0804 - accuracy: 0.2529 - val_loss: 0.2948 - val_accuracy: 0.6061\n",
      "Epoch 25/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0758 - accuracy: 0.2452 - val_loss: 0.2958 - val_accuracy: 0.6667\n",
      "Epoch 26/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0741 - accuracy: 0.2261 - val_loss: 0.3011 - val_accuracy: 0.5758\n",
      "Epoch 27/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0670 - accuracy: 0.2375 - val_loss: 0.2989 - val_accuracy: 0.6061\n",
      "Epoch 28/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0659 - accuracy: 0.2146 - val_loss: 0.3130 - val_accuracy: 0.5758\n",
      "Epoch 29/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0677 - accuracy: 0.2720 - val_loss: 0.3139 - val_accuracy: 0.5455\n",
      "Epoch 30/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0651 - accuracy: 0.2261 - val_loss: 0.2981 - val_accuracy: 0.6061\n",
      "Epoch 31/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0562 - accuracy: 0.2375 - val_loss: 0.2995 - val_accuracy: 0.6364\n",
      "Epoch 32/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0533 - accuracy: 0.1992 - val_loss: 0.3079 - val_accuracy: 0.5758\n",
      "Epoch 33/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0527 - accuracy: 0.2452 - val_loss: 0.3080 - val_accuracy: 0.5455\n",
      "Epoch 34/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0562 - accuracy: 0.2452 - val_loss: 0.3052 - val_accuracy: 0.6364\n",
      "Epoch 35/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0465 - accuracy: 0.2107 - val_loss: 0.3024 - val_accuracy: 0.5758\n",
      "Epoch 36/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0433 - accuracy: 0.2261 - val_loss: 0.3092 - val_accuracy: 0.5455\n",
      "Epoch 37/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0382 - accuracy: 0.2069 - val_loss: 0.2997 - val_accuracy: 0.5758\n",
      "Epoch 38/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0343 - accuracy: 0.2222 - val_loss: 0.2999 - val_accuracy: 0.5455\n",
      "Epoch 39/400\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0331 - accuracy: 0.1916 - val_loss: 0.3064 - val_accuracy: 0.5455\n",
      "Epoch 40/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0322 - accuracy: 0.2414 - val_loss: 0.3027 - val_accuracy: 0.5455\n",
      "Epoch 41/400\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0285 - accuracy: 0.1916 - val_loss: 0.3032 - val_accuracy: 0.5758\n",
      "Epoch 42/400\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0263 - accuracy: 0.2261 - val_loss: 0.3046 - val_accuracy: 0.5455\n",
      "Epoch 43/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0247 - accuracy: 0.1571 - val_loss: 0.3054 - val_accuracy: 0.5455\n",
      "Epoch 44/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0230 - accuracy: 0.1762 - val_loss: 0.3060 - val_accuracy: 0.5758\n",
      "Epoch 45/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0215 - accuracy: 0.1686 - val_loss: 0.3094 - val_accuracy: 0.5455\n",
      "Epoch 46/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0205 - accuracy: 0.2146 - val_loss: 0.3137 - val_accuracy: 0.5758\n",
      "Epoch 47/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0202 - accuracy: 0.1954 - val_loss: 0.3103 - val_accuracy: 0.5758\n",
      "Epoch 48/400\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0194 - accuracy: 0.2184 - val_loss: 0.3103 - val_accuracy: 0.5455\n",
      "Epoch 49/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0173 - accuracy: 0.1916 - val_loss: 0.3130 - val_accuracy: 0.5152\n",
      "Epoch 50/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0154 - accuracy: 0.1954 - val_loss: 0.3279 - val_accuracy: 0.5455\n",
      "Epoch 51/400\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0183 - accuracy: 0.2414 - val_loss: 0.3157 - val_accuracy: 0.5152\n",
      "Epoch 52/400\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0162 - accuracy: 0.1801 - val_loss: 0.3167 - val_accuracy: 0.5455\n",
      "Epoch 53/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0135 - accuracy: 0.1839 - val_loss: 0.3163 - val_accuracy: 0.5152\n",
      "Epoch 54/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0136 - accuracy: 0.2490 - val_loss: 0.3146 - val_accuracy: 0.5455\n",
      "Epoch 55/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0101 - accuracy: 0.1724 - val_loss: 0.3169 - val_accuracy: 0.5152\n",
      "Epoch 56/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0103 - accuracy: 0.1456 - val_loss: 0.3199 - val_accuracy: 0.5152\n",
      "Epoch 57/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0091 - accuracy: 0.1648 - val_loss: 0.3209 - val_accuracy: 0.5152\n",
      "Epoch 58/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0087 - accuracy: 0.2261 - val_loss: 0.3200 - val_accuracy: 0.5152\n",
      "Epoch 59/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0074 - accuracy: 0.1341 - val_loss: 0.3219 - val_accuracy: 0.5152\n",
      "Epoch 60/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0068 - accuracy: 0.2184 - val_loss: 0.3223 - val_accuracy: 0.5152\n",
      "Epoch 61/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0062 - accuracy: 0.1418 - val_loss: 0.3217 - val_accuracy: 0.5152\n",
      "Epoch 62/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0060 - accuracy: 0.2222 - val_loss: 0.3211 - val_accuracy: 0.5152\n",
      "Epoch 63/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0056 - accuracy: 0.2069 - val_loss: 0.3211 - val_accuracy: 0.5152\n",
      "Epoch 64/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0056 - accuracy: 0.1877 - val_loss: 0.3195 - val_accuracy: 0.5152\n",
      "Epoch 65/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0045 - accuracy: 0.2069 - val_loss: 0.3204 - val_accuracy: 0.5152\n",
      "Epoch 66/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0046 - accuracy: 0.1916 - val_loss: 0.3243 - val_accuracy: 0.5152\n",
      "Epoch 67/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0041 - accuracy: 0.1762 - val_loss: 0.3259 - val_accuracy: 0.5455\n",
      "Epoch 68/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0038 - accuracy: 0.2031 - val_loss: 0.3270 - val_accuracy: 0.5152\n",
      "Epoch 69/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 0.1149 - val_loss: 0.3252 - val_accuracy: 0.5152\n",
      "Epoch 70/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0036 - accuracy: 0.2261 - val_loss: 0.3284 - val_accuracy: 0.5152\n",
      "Epoch 71/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0055 - accuracy: 0.2031 - val_loss: 0.3289 - val_accuracy: 0.5455\n",
      "Epoch 72/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0054 - accuracy: 0.2261 - val_loss: 0.3286 - val_accuracy: 0.5152\n",
      "Epoch 73/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0050 - accuracy: 0.1916 - val_loss: 0.3305 - val_accuracy: 0.5152\n",
      "Epoch 74/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0049 - accuracy: 0.1992 - val_loss: 0.3336 - val_accuracy: 0.5455\n",
      "Epoch 75/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0052 - accuracy: 0.1762 - val_loss: 0.3353 - val_accuracy: 0.5152\n",
      "Epoch 76/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0065 - accuracy: 0.2797 - val_loss: 0.3289 - val_accuracy: 0.5455\n",
      "Epoch 77/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0037 - accuracy: 0.2605 - val_loss: 0.3294 - val_accuracy: 0.5455\n",
      "Epoch 78/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0029 - accuracy: 0.1609 - val_loss: 0.3321 - val_accuracy: 0.5455\n",
      "Epoch 79/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0027 - accuracy: 0.2184 - val_loss: 0.3338 - val_accuracy: 0.5152\n",
      "Epoch 80/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0019 - accuracy: 0.1877 - val_loss: 0.3360 - val_accuracy: 0.5455\n",
      "Epoch 81/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0025 - accuracy: 0.1379 - val_loss: 0.3356 - val_accuracy: 0.5455\n",
      "Epoch 82/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0014 - accuracy: 0.2567 - val_loss: 0.3363 - val_accuracy: 0.5152\n",
      "Epoch 83/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 0.1264 - val_loss: 0.3375 - val_accuracy: 0.5758\n",
      "Epoch 84/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0010 - accuracy: 0.1839 - val_loss: 0.3386 - val_accuracy: 0.5758\n",
      "Epoch 85/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.6055e-04 - accuracy: 0.2031 - val_loss: 0.3388 - val_accuracy: 0.5455\n",
      "Epoch 86/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0012 - accuracy: 0.1034 - val_loss: 0.3391 - val_accuracy: 0.5758\n",
      "Epoch 87/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.7109e-04 - accuracy: 0.2567 - val_loss: 0.3397 - val_accuracy: 0.5152\n",
      "Epoch 88/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.3835e-04 - accuracy: 0.1303 - val_loss: 0.3393 - val_accuracy: 0.5455\n",
      "Epoch 89/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.4829e-04 - accuracy: 0.2375 - val_loss: 0.3404 - val_accuracy: 0.5455\n",
      "Epoch 90/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 7.2402e-04 - accuracy: 0.1303 - val_loss: 0.3418 - val_accuracy: 0.5758\n",
      "Epoch 91/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.8973e-04 - accuracy: 0.2222 - val_loss: 0.3423 - val_accuracy: 0.5455\n",
      "Epoch 92/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.1375e-04 - accuracy: 0.1418 - val_loss: 0.3418 - val_accuracy: 0.5758\n",
      "Epoch 93/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.1811e-04 - accuracy: 0.2452 - val_loss: 0.3417 - val_accuracy: 0.5455\n",
      "Epoch 94/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.0944e-04 - accuracy: 0.1724 - val_loss: 0.3412 - val_accuracy: 0.5455\n",
      "Epoch 95/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.6972e-04 - accuracy: 0.1533 - val_loss: 0.3413 - val_accuracy: 0.5758\n",
      "Epoch 96/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.3879e-04 - accuracy: 0.2605 - val_loss: 0.3427 - val_accuracy: 0.5455\n",
      "Epoch 97/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.5864e-04 - accuracy: 0.1686 - val_loss: 0.3434 - val_accuracy: 0.5455\n",
      "Epoch 98/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 7.0864e-04 - accuracy: 0.2452 - val_loss: 0.3434 - val_accuracy: 0.5455\n",
      "Epoch 99/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.4789e-04 - accuracy: 0.1571 - val_loss: 0.3439 - val_accuracy: 0.5758\n",
      "Epoch 100/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.5432e-04 - accuracy: 0.2567 - val_loss: 0.3424 - val_accuracy: 0.5758\n",
      "Epoch 101/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.5969e-04 - accuracy: 0.1111 - val_loss: 0.3409 - val_accuracy: 0.5455\n",
      "Epoch 102/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.0786e-04 - accuracy: 0.2682 - val_loss: 0.3408 - val_accuracy: 0.5455\n",
      "Epoch 103/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.5603e-04 - accuracy: 0.1609 - val_loss: 0.3430 - val_accuracy: 0.5455\n",
      "Epoch 104/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.7772e-04 - accuracy: 0.2184 - val_loss: 0.3447 - val_accuracy: 0.5455\n",
      "Epoch 105/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.9146e-04 - accuracy: 0.2529 - val_loss: 0.3445 - val_accuracy: 0.5455\n",
      "Epoch 106/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.1043e-04 - accuracy: 0.1418 - val_loss: 0.3436 - val_accuracy: 0.5455\n",
      "Epoch 107/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.9006e-04 - accuracy: 0.1877 - val_loss: 0.3431 - val_accuracy: 0.5455\n",
      "Epoch 108/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.7861e-04 - accuracy: 0.2031 - val_loss: 0.3432 - val_accuracy: 0.5455\n",
      "Epoch 109/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.9444e-04 - accuracy: 0.1571 - val_loss: 0.3431 - val_accuracy: 0.5152\n",
      "Epoch 110/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.8270e-04 - accuracy: 0.2107 - val_loss: 0.3427 - val_accuracy: 0.5455\n",
      "Epoch 111/400\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 2.2149e-04 - accuracy: 0.2146 - val_loss: 0.3424 - val_accuracy: 0.5455\n",
      "Epoch 112/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.0170e-04 - accuracy: 0.2069 - val_loss: 0.3428 - val_accuracy: 0.5455\n",
      "Epoch 113/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 2.0610e-04 - accuracy: 0.2874 - val_loss: 0.3439 - val_accuracy: 0.5455\n",
      "Epoch 114/400\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.5519e-04 - accuracy: 0.1264 - val_loss: 0.3445 - val_accuracy: 0.5455\n",
      "Epoch 115/400\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.3884e-04 - accuracy: 0.2337 - val_loss: 0.3442 - val_accuracy: 0.5455\n",
      "Epoch 116/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 32ms/step - loss: 1.2417e-04 - accuracy: 0.1034 - val_loss: 0.3443 - val_accuracy: 0.5455\n",
      "Epoch 117/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.8583e-04 - accuracy: 0.3103 - val_loss: 0.3451 - val_accuracy: 0.5455\n",
      "Epoch 118/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.4666e-05 - accuracy: 0.1188 - val_loss: 0.3456 - val_accuracy: 0.5152\n",
      "Epoch 119/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 8.1528e-05 - accuracy: 0.2797 - val_loss: 0.3454 - val_accuracy: 0.5455\n",
      "Epoch 120/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.2950e-05 - accuracy: 0.0805 - val_loss: 0.3447 - val_accuracy: 0.5455\n",
      "Epoch 121/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.1776e-05 - accuracy: 0.3487 - val_loss: 0.3448 - val_accuracy: 0.5455\n",
      "Epoch 122/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.4406e-05 - accuracy: 0.0881 - val_loss: 0.3445 - val_accuracy: 0.5455\n",
      "Epoch 123/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.2203e-05 - accuracy: 0.3602 - val_loss: 0.3449 - val_accuracy: 0.5455\n",
      "Epoch 124/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.9703e-05 - accuracy: 0.0920 - val_loss: 0.3447 - val_accuracy: 0.5455\n",
      "Epoch 125/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.1408e-05 - accuracy: 0.2989 - val_loss: 0.3449 - val_accuracy: 0.5455\n",
      "Epoch 126/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.7465e-05 - accuracy: 0.1839 - val_loss: 0.3454 - val_accuracy: 0.5455\n",
      "Epoch 127/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.6491e-05 - accuracy: 0.1648 - val_loss: 0.3456 - val_accuracy: 0.5455\n",
      "Epoch 128/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.2341e-05 - accuracy: 0.1954 - val_loss: 0.3452 - val_accuracy: 0.5152\n",
      "Epoch 129/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.0779e-05 - accuracy: 0.1877 - val_loss: 0.3448 - val_accuracy: 0.5152\n",
      "Epoch 130/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.3149e-05 - accuracy: 0.2644 - val_loss: 0.3449 - val_accuracy: 0.5152\n",
      "Epoch 131/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3514e-05 - accuracy: 0.1609 - val_loss: 0.3448 - val_accuracy: 0.5152\n",
      "Epoch 132/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.9949e-05 - accuracy: 0.2414 - val_loss: 0.3447 - val_accuracy: 0.5152\n",
      "Epoch 133/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.1528e-05 - accuracy: 0.1226 - val_loss: 0.3447 - val_accuracy: 0.5152\n",
      "Epoch 134/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.5351e-05 - accuracy: 0.1877 - val_loss: 0.3451 - val_accuracy: 0.5152\n",
      "Epoch 135/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3778e-05 - accuracy: 0.1418 - val_loss: 0.3453 - val_accuracy: 0.5152\n",
      "Epoch 136/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.1829e-05 - accuracy: 0.2337 - val_loss: 0.3452 - val_accuracy: 0.5152\n",
      "Epoch 137/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.3168e-05 - accuracy: 0.1533 - val_loss: 0.3451 - val_accuracy: 0.5152\n",
      "Epoch 138/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.9679e-05 - accuracy: 0.2452 - val_loss: 0.3451 - val_accuracy: 0.5152\n",
      "Epoch 139/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.7256e-05 - accuracy: 0.1648 - val_loss: 0.3452 - val_accuracy: 0.5152\n",
      "Epoch 140/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.8387e-05 - accuracy: 0.1418 - val_loss: 0.3451 - val_accuracy: 0.5152\n",
      "Epoch 141/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.0781e-05 - accuracy: 0.2835 - val_loss: 0.3452 - val_accuracy: 0.5152\n",
      "Epoch 142/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.4106e-05 - accuracy: 0.1533 - val_loss: 0.3456 - val_accuracy: 0.5152\n",
      "Epoch 143/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.5625e-05 - accuracy: 0.1992 - val_loss: 0.3458 - val_accuracy: 0.5152\n",
      "Epoch 144/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.5993e-05 - accuracy: 0.2337 - val_loss: 0.3456 - val_accuracy: 0.5152\n",
      "Epoch 145/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0754e-05 - accuracy: 0.1456 - val_loss: 0.3455 - val_accuracy: 0.5152\n",
      "Epoch 146/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.0252e-05 - accuracy: 0.2835 - val_loss: 0.3458 - val_accuracy: 0.5152\n",
      "Epoch 147/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 8.8243e-06 - accuracy: 0.1379 - val_loss: 0.3459 - val_accuracy: 0.5152\n",
      "Epoch 148/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 9.5063e-06 - accuracy: 0.2682 - val_loss: 0.3460 - val_accuracy: 0.5152\n",
      "Epoch 149/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 8.4151e-06 - accuracy: 0.1801 - val_loss: 0.3458 - val_accuracy: 0.5152\n",
      "Epoch 150/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 8.0989e-06 - accuracy: 0.2261 - val_loss: 0.3459 - val_accuracy: 0.5152\n",
      "Epoch 151/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.8309e-06 - accuracy: 0.2299 - val_loss: 0.3460 - val_accuracy: 0.5152\n",
      "Epoch 152/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 7.1866e-06 - accuracy: 0.1992 - val_loss: 0.3461 - val_accuracy: 0.5152\n",
      "Epoch 153/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 6.1816e-06 - accuracy: 0.2069 - val_loss: 0.3461 - val_accuracy: 0.5152\n",
      "Epoch 154/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.8021e-06 - accuracy: 0.2069 - val_loss: 0.3460 - val_accuracy: 0.5152\n",
      "Epoch 155/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 5.4324e-06 - accuracy: 0.1992 - val_loss: 0.3461 - val_accuracy: 0.5152\n",
      "Epoch 156/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 6.0635e-06 - accuracy: 0.1954 - val_loss: 0.3462 - val_accuracy: 0.5152\n",
      "Epoch 157/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.3207e-06 - accuracy: 0.2337 - val_loss: 0.3461 - val_accuracy: 0.5152\n",
      "Epoch 158/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3520e-06 - accuracy: 0.1839 - val_loss: 0.3459 - val_accuracy: 0.5152\n",
      "Epoch 159/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.4570e-06 - accuracy: 0.3716 - val_loss: 0.3461 - val_accuracy: 0.5152\n",
      "Epoch 160/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 5.0336e-06 - accuracy: 0.1303 - val_loss: 0.3461 - val_accuracy: 0.5455\n",
      "Epoch 161/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.9175e-06 - accuracy: 0.2452 - val_loss: 0.3462 - val_accuracy: 0.5152\n",
      "Epoch 162/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.5138e-06 - accuracy: 0.1724 - val_loss: 0.3461 - val_accuracy: 0.5455\n",
      "Epoch 163/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 3.6493e-06 - accuracy: 0.2222 - val_loss: 0.3462 - val_accuracy: 0.5152\n",
      "Epoch 164/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 3.1288e-06 - accuracy: 0.2529 - val_loss: 0.3462 - val_accuracy: 0.5152\n",
      "Epoch 165/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.0937e-06 - accuracy: 0.2146 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 166/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.6875e-06 - accuracy: 0.2759 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 167/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.4019e-06 - accuracy: 0.1188 - val_loss: 0.3462 - val_accuracy: 0.5152\n",
      "Epoch 168/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.3328e-06 - accuracy: 0.2989 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 169/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.1252e-06 - accuracy: 0.2261 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 170/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.4028e-06 - accuracy: 0.1762 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 171/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 2.2840e-06 - accuracy: 0.1916 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 172/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.9317e-06 - accuracy: 0.1762 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 173/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 3.6113e-06 - accuracy: 0.3678 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 174/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 2.3155e-06 - accuracy: 0.1341 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 175/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.3607e-06 - accuracy: 0.1916 - val_loss: 0.3462 - val_accuracy: 0.5152\n",
      "Epoch 176/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.8028e-06 - accuracy: 0.3257 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 177/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.6190e-06 - accuracy: 0.1111 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 178/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.4949e-06 - accuracy: 0.2567 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 179/400\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.8598e-06 - accuracy: 0.1379 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 180/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.7466e-06 - accuracy: 0.2759 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 181/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.3803e-06 - accuracy: 0.1992 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 182/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1399e-06 - accuracy: 0.2069 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 183/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1206e-06 - accuracy: 0.2261 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 184/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.0641e-06 - accuracy: 0.2682 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 185/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.7312e-07 - accuracy: 0.1724 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 186/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0281e-06 - accuracy: 0.1992 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 187/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.8283e-07 - accuracy: 0.2567 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 188/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.8824e-07 - accuracy: 0.3448 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 189/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.8278e-07 - accuracy: 0.1379 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 190/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.0162e-06 - accuracy: 0.2759 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 191/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.8019e-07 - accuracy: 0.2031 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 192/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1995e-06 - accuracy: 0.1456 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 193/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.1786e-07 - accuracy: 0.3410 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 194/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0581e-06 - accuracy: 0.1303 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 195/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.1698e-07 - accuracy: 0.2261 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 196/400\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.2249e-06 - accuracy: 0.2567 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 197/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.1294e-06 - accuracy: 0.1034 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 198/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.0379e-06 - accuracy: 0.2874 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 199/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.8376e-06 - accuracy: 0.2529 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 200/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.3836e-06 - accuracy: 0.1111 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 201/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.6164e-06 - accuracy: 0.2759 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 202/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.9927e-07 - accuracy: 0.2069 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 203/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.5602e-07 - accuracy: 0.2069 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 204/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.6597e-07 - accuracy: 0.2261 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 205/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.6725e-07 - accuracy: 0.2031 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 206/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 7.3467e-07 - accuracy: 0.2452 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 207/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.6618e-07 - accuracy: 0.2414 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 208/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.7871e-07 - accuracy: 0.1877 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 209/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.8744e-07 - accuracy: 0.3218 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 210/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.4032e-07 - accuracy: 0.1801 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 211/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.5434e-07 - accuracy: 0.2222 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 212/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.2122e-07 - accuracy: 0.2682 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 213/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.7598e-07 - accuracy: 0.2299 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 214/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.6611e-07 - accuracy: 0.1801 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 215/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.5058e-07 - accuracy: 0.3142 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 216/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.0519e-07 - accuracy: 0.1609 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 217/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.8009e-07 - accuracy: 0.2529 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 218/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.8178e-07 - accuracy: 0.2644 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 219/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.9630e-07 - accuracy: 0.1877 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 220/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.3381e-07 - accuracy: 0.2490 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 221/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5728e-07 - accuracy: 0.2337 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 222/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 2.8773e-07 - accuracy: 0.1609 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 223/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.3337e-07 - accuracy: 0.2529 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 224/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.0094e-07 - accuracy: 0.1379 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 225/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.8741e-07 - accuracy: 0.1916 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 226/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.1375e-07 - accuracy: 0.3027 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 227/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.7642e-07 - accuracy: 0.1533 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 228/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 24ms/step - loss: 1.8554e-07 - accuracy: 0.1839 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 229/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.6612e-07 - accuracy: 0.2682 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 230/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.5345e-07 - accuracy: 0.2261 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 231/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.3440e-07 - accuracy: 0.2529 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 232/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.4795e-07 - accuracy: 0.2375 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 233/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.2089e-07 - accuracy: 0.1992 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 234/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.1875e-07 - accuracy: 0.2950 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 235/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.1590e-07 - accuracy: 0.2031 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 236/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.0015e-07 - accuracy: 0.1379 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 237/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0979e-07 - accuracy: 0.3065 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 238/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.0841e-07 - accuracy: 0.2452 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 239/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.0252e-07 - accuracy: 0.1379 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 240/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.4344e-07 - accuracy: 0.2299 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 241/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.3327e-07 - accuracy: 0.2375 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 242/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.3470e-07 - accuracy: 0.3027 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 243/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.4837e-07 - accuracy: 0.2222 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 244/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.6918e-07 - accuracy: 0.1034 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 245/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.5551e-07 - accuracy: 0.3180 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 246/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.4962e-07 - accuracy: 0.2069 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 247/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.0480e-08 - accuracy: 0.1456 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 248/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.8183e-08 - accuracy: 0.2912 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 249/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 7.0143e-08 - accuracy: 0.2031 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 250/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.3290e-08 - accuracy: 0.1111 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 251/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.4497e-08 - accuracy: 0.2797 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 252/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.2253e-08 - accuracy: 0.2567 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 253/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 6.7705e-08 - accuracy: 0.1916 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 254/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.7147e-08 - accuracy: 0.2375 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 255/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.4835e-08 - accuracy: 0.2797 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 256/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.3792e-08 - accuracy: 0.1992 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 257/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.0943e-08 - accuracy: 0.2490 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 258/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.1439e-08 - accuracy: 0.3142 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 259/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.2263e-08 - accuracy: 0.1686 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 260/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3203e-08 - accuracy: 0.2107 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 261/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4749e-08 - accuracy: 0.2682 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 262/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.7852e-08 - accuracy: 0.2529 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 263/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5785e-08 - accuracy: 0.3218 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 264/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.1732e-08 - accuracy: 0.1839 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 265/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.9100e-08 - accuracy: 0.1954 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 266/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8408e-08 - accuracy: 0.2950 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 267/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.8110e-08 - accuracy: 0.1954 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 268/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.5205e-08 - accuracy: 0.1801 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 269/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.4519e-08 - accuracy: 0.2567 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 270/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.1270e-08 - accuracy: 0.2605 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 271/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.7222e-08 - accuracy: 0.2759 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 272/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.8844e-08 - accuracy: 0.2529 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 273/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.1115e-07 - accuracy: 0.1762 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 274/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.2514e-07 - accuracy: 0.1877 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 275/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.8820e-07 - accuracy: 0.2375 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 276/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.0503e-07 - accuracy: 0.2375 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 277/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 3.3453e-07 - accuracy: 0.2299 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 278/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3210e-07 - accuracy: 0.2031 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 279/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4103e-07 - accuracy: 0.2490 - val_loss: 0.3468 - val_accuracy: 0.5152\n",
      "Epoch 280/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.9563e-07 - accuracy: 0.2644 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 281/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.0318e-06 - accuracy: 0.1686 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 282/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 7.0708e-07 - accuracy: 0.2261 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 283/400\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0977e-06 - accuracy: 0.1686 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 284/400\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 6.9892e-07 - accuracy: 0.2490 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 285/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.4121e-07 - accuracy: 0.1456 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 286/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.8179e-07 - accuracy: 0.1916 - val_loss: 0.3468 - val_accuracy: 0.5152\n",
      "Epoch 287/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.8175e-07 - accuracy: 0.2567 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 288/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 8.8125e-07 - accuracy: 0.2720 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 289/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.0861e-06 - accuracy: 0.2031 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 290/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.0471e-06 - accuracy: 0.1992 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 291/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.1992e-06 - accuracy: 0.2146 - val_loss: 0.3468 - val_accuracy: 0.5152\n",
      "Epoch 292/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8327e-06 - accuracy: 0.2720 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 293/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.6296e-06 - accuracy: 0.1724 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 294/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.7457e-06 - accuracy: 0.1533 - val_loss: 0.3471 - val_accuracy: 0.5152\n",
      "Epoch 295/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.1913e-05 - accuracy: 0.2529 - val_loss: 0.3470 - val_accuracy: 0.5152\n",
      "Epoch 296/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.2371e-05 - accuracy: 0.2605 - val_loss: 0.3468 - val_accuracy: 0.5152\n",
      "Epoch 297/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 6.8139e-06 - accuracy: 0.2107 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 298/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.9445e-06 - accuracy: 0.1533 - val_loss: 0.3471 - val_accuracy: 0.5152\n",
      "Epoch 299/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3474e-06 - accuracy: 0.1877 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 300/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.5314e-06 - accuracy: 0.2682 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 301/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.3791e-06 - accuracy: 0.2299 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 302/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.4177e-06 - accuracy: 0.1264 - val_loss: 0.3467 - val_accuracy: 0.5152\n",
      "Epoch 303/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.0103e-06 - accuracy: 0.1724 - val_loss: 0.3464 - val_accuracy: 0.5152\n",
      "Epoch 304/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.2376e-06 - accuracy: 0.2337 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 305/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.5992e-06 - accuracy: 0.3180 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 306/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.6315e-06 - accuracy: 0.2031 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 307/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 3.4497e-06 - accuracy: 0.0651 - val_loss: 0.3468 - val_accuracy: 0.5152\n",
      "Epoch 308/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 9.2159e-06 - accuracy: 0.1533 - val_loss: 0.3468 - val_accuracy: 0.5152\n",
      "Epoch 309/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 1.1233e-05 - accuracy: 0.2337 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 310/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.2822e-05 - accuracy: 0.2644 - val_loss: 0.3472 - val_accuracy: 0.5152\n",
      "Epoch 311/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.7858e-05 - accuracy: 0.1188 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 312/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.0434e-05 - accuracy: 0.2529 - val_loss: 0.3465 - val_accuracy: 0.5152\n",
      "Epoch 313/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.2291e-05 - accuracy: 0.2414 - val_loss: 0.3472 - val_accuracy: 0.5152\n",
      "Epoch 314/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.2259e-05 - accuracy: 0.1494 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 315/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 5.0027e-05 - accuracy: 0.2146 - val_loss: 0.3469 - val_accuracy: 0.5152\n",
      "Epoch 316/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 9.1331e-05 - accuracy: 0.1762 - val_loss: 0.3466 - val_accuracy: 0.5152\n",
      "Epoch 317/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 2.4138e-04 - accuracy: 0.1724 - val_loss: 0.3477 - val_accuracy: 0.5152\n",
      "Epoch 318/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.9659e-04 - accuracy: 0.2069 - val_loss: 0.3487 - val_accuracy: 0.5455\n",
      "Epoch 319/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.1410e-04 - accuracy: 0.0881 - val_loss: 0.3498 - val_accuracy: 0.5455\n",
      "Epoch 320/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.6756e-04 - accuracy: 0.1916 - val_loss: 0.3458 - val_accuracy: 0.5455\n",
      "Epoch 321/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3695e-04 - accuracy: 0.2529 - val_loss: 0.3471 - val_accuracy: 0.4848\n",
      "Epoch 322/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0010 - accuracy: 0.2874 - val_loss: 0.3453 - val_accuracy: 0.5455\n",
      "Epoch 323/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0021 - accuracy: 0.2682 - val_loss: 0.3510 - val_accuracy: 0.4848\n",
      "Epoch 324/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 0.2644 - val_loss: 0.3452 - val_accuracy: 0.5455\n",
      "Epoch 325/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0022 - accuracy: 0.1839 - val_loss: 0.3447 - val_accuracy: 0.4848\n",
      "Epoch 326/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.2184 - val_loss: 0.3482 - val_accuracy: 0.5152\n",
      "Epoch 327/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.0069 - accuracy: 0.3448 - val_loss: 0.3629 - val_accuracy: 0.5152\n",
      "Epoch 328/400\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0108 - accuracy: 0.2720 - val_loss: 0.3526 - val_accuracy: 0.4848\n",
      "Epoch 329/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0103 - accuracy: 0.5517 - val_loss: 0.3449 - val_accuracy: 0.4545\n",
      "Epoch 330/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0080 - accuracy: 0.3985 - val_loss: 0.3318 - val_accuracy: 0.5455\n",
      "Epoch 331/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0070 - accuracy: 0.6935 - val_loss: 0.3287 - val_accuracy: 0.5758\n",
      "Epoch 332/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0035 - accuracy: 0.5824 - val_loss: 0.3299 - val_accuracy: 0.5758\n",
      "Epoch 333/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0020 - accuracy: 0.7203 - val_loss: 0.3336 - val_accuracy: 0.5758\n",
      "Epoch 334/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.0018 - accuracy: 0.6897 - val_loss: 0.3416 - val_accuracy: 0.5758\n",
      "Epoch 335/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0017 - accuracy: 0.6743 - val_loss: 0.3400 - val_accuracy: 0.6061\n",
      "Epoch 336/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.0012 - accuracy: 0.7816 - val_loss: 0.3405 - val_accuracy: 0.6061\n",
      "Epoch 337/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.6820 - val_loss: 0.3378 - val_accuracy: 0.5758\n",
      "Epoch 338/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 8.7054e-04 - accuracy: 0.7893 - val_loss: 0.3401 - val_accuracy: 0.5758\n",
      "Epoch 339/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3906e-04 - accuracy: 0.7471 - val_loss: 0.3411 - val_accuracy: 0.5758\n",
      "Epoch 340/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 25ms/step - loss: 3.2586e-04 - accuracy: 0.7663 - val_loss: 0.3398 - val_accuracy: 0.5758\n",
      "Epoch 341/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.1319e-04 - accuracy: 0.7510 - val_loss: 0.3400 - val_accuracy: 0.5758\n",
      "Epoch 342/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.6301e-04 - accuracy: 0.8046 - val_loss: 0.3394 - val_accuracy: 0.5758\n",
      "Epoch 343/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.0607e-04 - accuracy: 0.6897 - val_loss: 0.3379 - val_accuracy: 0.5758\n",
      "Epoch 344/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.7309e-04 - accuracy: 0.7969 - val_loss: 0.3396 - val_accuracy: 0.5758\n",
      "Epoch 345/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.4162e-04 - accuracy: 0.7625 - val_loss: 0.3426 - val_accuracy: 0.5758\n",
      "Epoch 346/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.1936e-04 - accuracy: 0.6935 - val_loss: 0.3437 - val_accuracy: 0.5758\n",
      "Epoch 347/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.3259e-04 - accuracy: 0.8238 - val_loss: 0.3415 - val_accuracy: 0.5758\n",
      "Epoch 348/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.5934e-04 - accuracy: 0.4521 - val_loss: 0.3395 - val_accuracy: 0.4545\n",
      "Epoch 349/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.0795e-04 - accuracy: 0.1992 - val_loss: 0.3394 - val_accuracy: 0.4848\n",
      "Epoch 350/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.9829e-05 - accuracy: 0.3065 - val_loss: 0.3405 - val_accuracy: 0.5758\n",
      "Epoch 351/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 6.5926e-05 - accuracy: 0.5670 - val_loss: 0.3405 - val_accuracy: 0.4848\n",
      "Epoch 352/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.0204e-05 - accuracy: 0.2529 - val_loss: 0.3411 - val_accuracy: 0.4848\n",
      "Epoch 353/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.9312e-05 - accuracy: 0.1762 - val_loss: 0.3413 - val_accuracy: 0.4848\n",
      "Epoch 354/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.2362e-05 - accuracy: 0.2490 - val_loss: 0.3404 - val_accuracy: 0.4848\n",
      "Epoch 355/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.6289e-05 - accuracy: 0.2261 - val_loss: 0.3407 - val_accuracy: 0.4848\n",
      "Epoch 356/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.8362e-05 - accuracy: 0.2644 - val_loss: 0.3411 - val_accuracy: 0.4848\n",
      "Epoch 357/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.8540e-05 - accuracy: 0.2031 - val_loss: 0.3413 - val_accuracy: 0.4848\n",
      "Epoch 358/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 2.7714e-05 - accuracy: 0.2682 - val_loss: 0.3412 - val_accuracy: 0.4848\n",
      "Epoch 359/400\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 5.3415e-05 - accuracy: 0.2069 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 360/400\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 4.8034e-05 - accuracy: 0.2337 - val_loss: 0.3424 - val_accuracy: 0.4848\n",
      "Epoch 361/400\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 1.5597e-05 - accuracy: 0.2375 - val_loss: 0.3422 - val_accuracy: 0.4848\n",
      "Epoch 362/400\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.4520e-05 - accuracy: 0.1916 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 363/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.2950e-05 - accuracy: 0.2529 - val_loss: 0.3427 - val_accuracy: 0.4848\n",
      "Epoch 364/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.2702e-05 - accuracy: 0.2031 - val_loss: 0.3424 - val_accuracy: 0.4848\n",
      "Epoch 365/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.8980e-06 - accuracy: 0.2337 - val_loss: 0.3417 - val_accuracy: 0.4848\n",
      "Epoch 366/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.6349e-06 - accuracy: 0.2031 - val_loss: 0.3415 - val_accuracy: 0.4848\n",
      "Epoch 367/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 9.0150e-06 - accuracy: 0.2375 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 368/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1459e-05 - accuracy: 0.2682 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 369/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.5294e-05 - accuracy: 0.1609 - val_loss: 0.3416 - val_accuracy: 0.4848\n",
      "Epoch 370/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.9542e-06 - accuracy: 0.2912 - val_loss: 0.3417 - val_accuracy: 0.4848\n",
      "Epoch 371/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 5.7961e-06 - accuracy: 0.1494 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 372/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.1064e-06 - accuracy: 0.1877 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 373/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5865e-06 - accuracy: 0.3218 - val_loss: 0.3417 - val_accuracy: 0.4848\n",
      "Epoch 374/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.9282e-06 - accuracy: 0.1341 - val_loss: 0.3417 - val_accuracy: 0.4848\n",
      "Epoch 375/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.2646e-06 - accuracy: 0.3180 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 376/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.5622e-06 - accuracy: 0.1724 - val_loss: 0.3418 - val_accuracy: 0.4848\n",
      "Epoch 377/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.3584e-06 - accuracy: 0.2375 - val_loss: 0.3416 - val_accuracy: 0.4848\n",
      "Epoch 378/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.6852e-06 - accuracy: 0.3448 - val_loss: 0.3416 - val_accuracy: 0.4848\n",
      "Epoch 379/400\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.9467e-06 - accuracy: 0.1686 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 380/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.5635e-06 - accuracy: 0.1762 - val_loss: 0.3418 - val_accuracy: 0.4848\n",
      "Epoch 381/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.6691e-06 - accuracy: 0.2797 - val_loss: 0.3417 - val_accuracy: 0.4848\n",
      "Epoch 382/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.4206e-06 - accuracy: 0.1648 - val_loss: 0.3418 - val_accuracy: 0.4848\n",
      "Epoch 383/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 8.3184e-07 - accuracy: 0.2950 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 384/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 7.9508e-07 - accuracy: 0.2720 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 385/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.7708e-06 - accuracy: 0.1648 - val_loss: 0.3418 - val_accuracy: 0.4848\n",
      "Epoch 386/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 2.5831e-06 - accuracy: 0.3027 - val_loss: 0.3418 - val_accuracy: 0.4848\n",
      "Epoch 387/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.8274e-06 - accuracy: 0.2107 - val_loss: 0.3417 - val_accuracy: 0.4848\n",
      "Epoch 388/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.7903e-06 - accuracy: 0.1571 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 389/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.6472e-06 - accuracy: 0.2912 - val_loss: 0.3421 - val_accuracy: 0.4848\n",
      "Epoch 390/400\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 1.5527e-06 - accuracy: 0.2414 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 391/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.2985e-06 - accuracy: 0.2031 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 392/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.0912e-06 - accuracy: 0.2682 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 393/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 6.4872e-07 - accuracy: 0.2375 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 394/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.1253e-07 - accuracy: 0.1839 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 395/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 5.9844e-07 - accuracy: 0.1916 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 396/400\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 6.7399e-07 - accuracy: 0.2605 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 397/400\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 5.3989e-07 - accuracy: 0.3142 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 398/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.1691e-06 - accuracy: 0.1494 - val_loss: 0.3420 - val_accuracy: 0.4848\n",
      "Epoch 399/400\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.0978e-06 - accuracy: 0.2375 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "Epoch 400/400\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 9.1950e-07 - accuracy: 0.3218 - val_loss: 0.3419 - val_accuracy: 0.4848\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1989 - accuracy: 0.4242\n",
      "Test accuracy: 0.42424243688583374\n"
     ]
    }
   ],
   "source": [
    "# Leela's Implementation\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(10, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(2)  # Use 2 output units for binary classification\n",
    "])\n",
    "\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.01,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=['mse'],\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "\n",
    "# Step 3: Train and evaluate model\n",
    "\n",
    "history2 = model.fit(X_train, Y_train, epochs=400, batch_size=50, \n",
    "                    validation_data=(X_val, Y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ba8416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['accuracy'], label='train')\n",
    "plt.plot(history2.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e25ea22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "14/14 [==============================] - 1s 28ms/step - loss: 0.2551 - accuracy: 0.4291 - val_loss: 0.2657 - val_accuracy: 0.4848\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2492 - accuracy: 0.4291 - val_loss: 0.2561 - val_accuracy: 0.4848\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2457 - accuracy: 0.4291 - val_loss: 0.2599 - val_accuracy: 0.4848\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2446 - accuracy: 0.4291 - val_loss: 0.2541 - val_accuracy: 0.4848\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.2426 - accuracy: 0.4291 - val_loss: 0.2537 - val_accuracy: 0.4848\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.2425 - accuracy: 0.4291 - val_loss: 0.2537 - val_accuracy: 0.4848\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2420 - accuracy: 0.4559 - val_loss: 0.2528 - val_accuracy: 0.5152\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2420 - accuracy: 0.4674 - val_loss: 0.2528 - val_accuracy: 0.5455\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2396 - accuracy: 0.4444 - val_loss: 0.2527 - val_accuracy: 0.5455\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.2377 - accuracy: 0.4406 - val_loss: 0.2583 - val_accuracy: 0.5455\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2364 - accuracy: 0.4444 - val_loss: 0.2587 - val_accuracy: 0.5455\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2347 - accuracy: 0.4636 - val_loss: 0.2694 - val_accuracy: 0.4545\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2351 - accuracy: 0.4559 - val_loss: 0.2526 - val_accuracy: 0.5152\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2321 - accuracy: 0.4559 - val_loss: 0.2569 - val_accuracy: 0.4545\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2397 - accuracy: 0.4291 - val_loss: 0.2560 - val_accuracy: 0.4848\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2289 - accuracy: 0.4483 - val_loss: 0.2612 - val_accuracy: 0.5152\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2285 - accuracy: 0.4674 - val_loss: 0.2513 - val_accuracy: 0.4848\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.2273 - accuracy: 0.4751 - val_loss: 0.2504 - val_accuracy: 0.4545\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2245 - accuracy: 0.4789 - val_loss: 0.2614 - val_accuracy: 0.5455\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2345 - accuracy: 0.4943 - val_loss: 0.2522 - val_accuracy: 0.4848\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2249 - accuracy: 0.4943 - val_loss: 0.2517 - val_accuracy: 0.5152\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2246 - accuracy: 0.5019 - val_loss: 0.2778 - val_accuracy: 0.5152\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2183 - accuracy: 0.4789 - val_loss: 0.2513 - val_accuracy: 0.5758\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.2130 - accuracy: 0.5057 - val_loss: 0.2702 - val_accuracy: 0.5455\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2302 - accuracy: 0.4866 - val_loss: 0.2994 - val_accuracy: 0.4242\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2130 - accuracy: 0.4943 - val_loss: 0.2560 - val_accuracy: 0.5455\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2154 - accuracy: 0.4828 - val_loss: 0.2983 - val_accuracy: 0.4848\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2123 - accuracy: 0.4674 - val_loss: 0.2528 - val_accuracy: 0.5152\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2086 - accuracy: 0.5019 - val_loss: 0.3148 - val_accuracy: 0.4848\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2116 - accuracy: 0.4904 - val_loss: 0.2576 - val_accuracy: 0.5455\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2108 - accuracy: 0.4981 - val_loss: 0.2536 - val_accuracy: 0.5152\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2137 - accuracy: 0.5019 - val_loss: 0.2883 - val_accuracy: 0.4848\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2056 - accuracy: 0.4943 - val_loss: 0.3139 - val_accuracy: 0.4848\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2089 - accuracy: 0.4751 - val_loss: 0.2503 - val_accuracy: 0.4848\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.2087 - accuracy: 0.4981 - val_loss: 0.2480 - val_accuracy: 0.4848\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1986 - accuracy: 0.4943 - val_loss: 0.2714 - val_accuracy: 0.4848\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1985 - accuracy: 0.5019 - val_loss: 0.3463 - val_accuracy: 0.5152\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2069 - accuracy: 0.4866 - val_loss: 0.3529 - val_accuracy: 0.5455\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2089 - accuracy: 0.4598 - val_loss: 0.2475 - val_accuracy: 0.4848\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1940 - accuracy: 0.4904 - val_loss: 0.2858 - val_accuracy: 0.5152\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1943 - accuracy: 0.4943 - val_loss: 0.3394 - val_accuracy: 0.5152\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.2103 - accuracy: 0.5019 - val_loss: 0.2911 - val_accuracy: 0.4848\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1933 - accuracy: 0.4828 - val_loss: 0.2851 - val_accuracy: 0.5455\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2137 - accuracy: 0.4598 - val_loss: 0.3068 - val_accuracy: 0.5152\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1933 - accuracy: 0.4751 - val_loss: 0.2515 - val_accuracy: 0.5152\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1891 - accuracy: 0.4828 - val_loss: 0.2585 - val_accuracy: 0.5152\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1951 - accuracy: 0.4828 - val_loss: 0.3270 - val_accuracy: 0.5152\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1886 - accuracy: 0.4789 - val_loss: 0.2641 - val_accuracy: 0.5152\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1876 - accuracy: 0.4981 - val_loss: 0.2560 - val_accuracy: 0.5152\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1852 - accuracy: 0.4789 - val_loss: 0.2941 - val_accuracy: 0.4848\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1863 - accuracy: 0.4866 - val_loss: 0.3068 - val_accuracy: 0.4545\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1844 - accuracy: 0.4943 - val_loss: 0.2583 - val_accuracy: 0.4848\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1758 - accuracy: 0.4828 - val_loss: 0.2529 - val_accuracy: 0.5152\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1825 - accuracy: 0.4828 - val_loss: 0.3109 - val_accuracy: 0.4545\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1837 - accuracy: 0.4828 - val_loss: 0.2846 - val_accuracy: 0.4848\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1785 - accuracy: 0.4866 - val_loss: 0.2659 - val_accuracy: 0.4848\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1763 - accuracy: 0.4866 - val_loss: 0.2586 - val_accuracy: 0.4848\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1811 - accuracy: 0.4789 - val_loss: 0.2844 - val_accuracy: 0.4848\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1891 - accuracy: 0.4866 - val_loss: 0.2639 - val_accuracy: 0.5152\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.4828 - val_loss: 0.3044 - val_accuracy: 0.5455\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2017 - accuracy: 0.4674 - val_loss: 0.2853 - val_accuracy: 0.4848\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1758 - accuracy: 0.4751 - val_loss: 0.2632 - val_accuracy: 0.5152\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1748 - accuracy: 0.4751 - val_loss: 0.4037 - val_accuracy: 0.5758\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1923 - accuracy: 0.4866 - val_loss: 0.2893 - val_accuracy: 0.4848\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1866 - accuracy: 0.4598 - val_loss: 0.2690 - val_accuracy: 0.4848\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1760 - accuracy: 0.4713 - val_loss: 0.2651 - val_accuracy: 0.4848\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1600 - accuracy: 0.4904 - val_loss: 0.2636 - val_accuracy: 0.4848\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1649 - accuracy: 0.4943 - val_loss: 0.3653 - val_accuracy: 0.5455\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1649 - accuracy: 0.4981 - val_loss: 0.2726 - val_accuracy: 0.4545\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.1596 - accuracy: 0.4828 - val_loss: 0.2819 - val_accuracy: 0.4848\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.1619 - accuracy: 0.4904 - val_loss: 0.3002 - val_accuracy: 0.4848\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.1598 - accuracy: 0.4904 - val_loss: 0.2670 - val_accuracy: 0.4545\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1532 - accuracy: 0.4943 - val_loss: 0.2654 - val_accuracy: 0.5152\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1623 - accuracy: 0.5019 - val_loss: 0.3033 - val_accuracy: 0.4848\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1564 - accuracy: 0.5019 - val_loss: 0.2752 - val_accuracy: 0.4848\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1583 - accuracy: 0.4904 - val_loss: 0.2813 - val_accuracy: 0.4545\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1538 - accuracy: 0.4981 - val_loss: 0.3314 - val_accuracy: 0.4848\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 0.2015 - accuracy: 0.4789 - val_loss: 0.3370 - val_accuracy: 0.5152\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1583 - accuracy: 0.4904 - val_loss: 0.2608 - val_accuracy: 0.4848\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1441 - accuracy: 0.4981 - val_loss: 0.4170 - val_accuracy: 0.5455\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1691 - accuracy: 0.5057 - val_loss: 0.2627 - val_accuracy: 0.4545\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1477 - accuracy: 0.4904 - val_loss: 0.2605 - val_accuracy: 0.4545\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1411 - accuracy: 0.4981 - val_loss: 0.2791 - val_accuracy: 0.4848\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1397 - accuracy: 0.5019 - val_loss: 0.2912 - val_accuracy: 0.4848\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1399 - accuracy: 0.5019 - val_loss: 0.2638 - val_accuracy: 0.4545\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1420 - accuracy: 0.5057 - val_loss: 0.4019 - val_accuracy: 0.5455\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1530 - accuracy: 0.5019 - val_loss: 0.2774 - val_accuracy: 0.4848\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1383 - accuracy: 0.5019 - val_loss: 0.3198 - val_accuracy: 0.5152\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1404 - accuracy: 0.5096 - val_loss: 0.3001 - val_accuracy: 0.5152\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1424 - accuracy: 0.4904 - val_loss: 0.2774 - val_accuracy: 0.5152\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1349 - accuracy: 0.4981 - val_loss: 0.2738 - val_accuracy: 0.5152\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1406 - accuracy: 0.4981 - val_loss: 0.3156 - val_accuracy: 0.5152\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.4943 - val_loss: 0.2667 - val_accuracy: 0.4848\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1398 - accuracy: 0.5057 - val_loss: 0.3037 - val_accuracy: 0.5152\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1440 - accuracy: 0.5019 - val_loss: 0.2718 - val_accuracy: 0.4545\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.1258 - accuracy: 0.5019 - val_loss: 0.2957 - val_accuracy: 0.5152\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1453 - accuracy: 0.5019 - val_loss: 0.2699 - val_accuracy: 0.4545\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1199 - accuracy: 0.5096 - val_loss: 0.3972 - val_accuracy: 0.4848\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1745 - accuracy: 0.5096 - val_loss: 0.4535 - val_accuracy: 0.5455\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1621 - accuracy: 0.4981 - val_loss: 0.2784 - val_accuracy: 0.4545\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1254 - accuracy: 0.4904 - val_loss: 0.3049 - val_accuracy: 0.4848\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1330 - accuracy: 0.4981 - val_loss: 0.2754 - val_accuracy: 0.4545\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1170 - accuracy: 0.5019 - val_loss: 0.2727 - val_accuracy: 0.4545\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1190 - accuracy: 0.5096 - val_loss: 0.2695 - val_accuracy: 0.4545\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1166 - accuracy: 0.5096 - val_loss: 0.3419 - val_accuracy: 0.5152\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1420 - accuracy: 0.5134 - val_loss: 0.2759 - val_accuracy: 0.4545\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.1119 - accuracy: 0.5096 - val_loss: 0.3547 - val_accuracy: 0.5152\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1149 - accuracy: 0.5134 - val_loss: 0.2707 - val_accuracy: 0.4848\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1016 - accuracy: 0.5096 - val_loss: 0.2691 - val_accuracy: 0.4545\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.5096 - val_loss: 0.3037 - val_accuracy: 0.5152\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1102 - accuracy: 0.5172 - val_loss: 0.4376 - val_accuracy: 0.5152\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1317 - accuracy: 0.5172 - val_loss: 0.2894 - val_accuracy: 0.5152\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.1054 - accuracy: 0.5096 - val_loss: 0.3642 - val_accuracy: 0.5455\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.1102 - accuracy: 0.5211 - val_loss: 0.2902 - val_accuracy: 0.4545\n",
      "Epoch 115/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1116 - accuracy: 0.4943 - val_loss: 0.2736 - val_accuracy: 0.4545\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1048 - accuracy: 0.5096 - val_loss: 0.2726 - val_accuracy: 0.4848\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0993 - accuracy: 0.5134 - val_loss: 0.2747 - val_accuracy: 0.4545\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1071 - accuracy: 0.5287 - val_loss: 0.3328 - val_accuracy: 0.4848\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1140 - accuracy: 0.5249 - val_loss: 0.4246 - val_accuracy: 0.4848\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.1373 - accuracy: 0.4943 - val_loss: 0.4437 - val_accuracy: 0.5455\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1160 - accuracy: 0.5211 - val_loss: 0.2932 - val_accuracy: 0.4848\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.5096 - val_loss: 0.2862 - val_accuracy: 0.4848\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0891 - accuracy: 0.5096 - val_loss: 0.2883 - val_accuracy: 0.5152\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0965 - accuracy: 0.5134 - val_loss: 0.3914 - val_accuracy: 0.5455\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0957 - accuracy: 0.5172 - val_loss: 0.2760 - val_accuracy: 0.4848\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0851 - accuracy: 0.5096 - val_loss: 0.2764 - val_accuracy: 0.4848\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 0.5057 - val_loss: 0.3121 - val_accuracy: 0.5152\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0845 - accuracy: 0.5134 - val_loss: 0.3459 - val_accuracy: 0.5455\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0916 - accuracy: 0.5172 - val_loss: 0.3019 - val_accuracy: 0.5152\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0811 - accuracy: 0.5172 - val_loss: 0.2876 - val_accuracy: 0.4848\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0829 - accuracy: 0.5134 - val_loss: 0.3121 - val_accuracy: 0.5152\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0902 - accuracy: 0.5172 - val_loss: 0.2852 - val_accuracy: 0.4848\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0791 - accuracy: 0.5211 - val_loss: 0.4272 - val_accuracy: 0.5758\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.5172 - val_loss: 0.3073 - val_accuracy: 0.4848\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0785 - accuracy: 0.5172 - val_loss: 0.3542 - val_accuracy: 0.4848\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0951 - accuracy: 0.5249 - val_loss: 0.3054 - val_accuracy: 0.5152\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.5211 - val_loss: 0.2924 - val_accuracy: 0.4848\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0701 - accuracy: 0.5249 - val_loss: 0.3328 - val_accuracy: 0.5152\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0730 - accuracy: 0.5172 - val_loss: 0.2967 - val_accuracy: 0.5152\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0661 - accuracy: 0.5172 - val_loss: 0.3006 - val_accuracy: 0.5152\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0661 - accuracy: 0.5249 - val_loss: 0.2950 - val_accuracy: 0.4848\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0609 - accuracy: 0.5172 - val_loss: 0.3458 - val_accuracy: 0.5455\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0743 - accuracy: 0.5326 - val_loss: 0.3463 - val_accuracy: 0.4545\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0699 - accuracy: 0.5134 - val_loss: 0.3459 - val_accuracy: 0.4848\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0732 - accuracy: 0.5287 - val_loss: 0.3027 - val_accuracy: 0.4848\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0611 - accuracy: 0.5249 - val_loss: 0.3170 - val_accuracy: 0.5152\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0577 - accuracy: 0.5402 - val_loss: 0.3274 - val_accuracy: 0.5455\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0660 - accuracy: 0.5211 - val_loss: 0.3254 - val_accuracy: 0.5455\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0708 - accuracy: 0.5211 - val_loss: 0.2950 - val_accuracy: 0.5152\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0532 - accuracy: 0.5211 - val_loss: 0.3246 - val_accuracy: 0.5455\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0609 - accuracy: 0.5249 - val_loss: 0.2963 - val_accuracy: 0.5455\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0557 - accuracy: 0.5287 - val_loss: 0.2991 - val_accuracy: 0.5152\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0559 - accuracy: 0.5326 - val_loss: 0.2940 - val_accuracy: 0.5455\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0490 - accuracy: 0.5249 - val_loss: 0.3304 - val_accuracy: 0.5152\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0543 - accuracy: 0.5326 - val_loss: 0.5539 - val_accuracy: 0.6061\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.1157 - accuracy: 0.5326 - val_loss: 0.3494 - val_accuracy: 0.5455\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0713 - accuracy: 0.5441 - val_loss: 0.2978 - val_accuracy: 0.4848\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0502 - accuracy: 0.5364 - val_loss: 0.3499 - val_accuracy: 0.5758\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0478 - accuracy: 0.5287 - val_loss: 0.2955 - val_accuracy: 0.5152\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0447 - accuracy: 0.5287 - val_loss: 0.3610 - val_accuracy: 0.5455\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0453 - accuracy: 0.5211 - val_loss: 0.3150 - val_accuracy: 0.5455\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0446 - accuracy: 0.5326 - val_loss: 0.3227 - val_accuracy: 0.5152\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0440 - accuracy: 0.5326 - val_loss: 0.4280 - val_accuracy: 0.4545\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0628 - accuracy: 0.5479 - val_loss: 0.3098 - val_accuracy: 0.5152\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0421 - accuracy: 0.5364 - val_loss: 0.3442 - val_accuracy: 0.5152\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0442 - accuracy: 0.5364 - val_loss: 0.3041 - val_accuracy: 0.5152\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0381 - accuracy: 0.5402 - val_loss: 0.3379 - val_accuracy: 0.5152\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0401 - accuracy: 0.5326 - val_loss: 0.3175 - val_accuracy: 0.5152\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0338 - accuracy: 0.5326 - val_loss: 0.3201 - val_accuracy: 0.5152\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.5287 - val_loss: 0.3153 - val_accuracy: 0.5152\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0354 - accuracy: 0.5326 - val_loss: 0.3538 - val_accuracy: 0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.5402 - val_loss: 0.3058 - val_accuracy: 0.5455\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0386 - accuracy: 0.5402 - val_loss: 0.3047 - val_accuracy: 0.5455\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.5517 - val_loss: 0.3128 - val_accuracy: 0.5455\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0296 - accuracy: 0.5479 - val_loss: 0.3222 - val_accuracy: 0.5455\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0320 - accuracy: 0.5441 - val_loss: 0.4197 - val_accuracy: 0.5455\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0460 - accuracy: 0.5441 - val_loss: 0.3107 - val_accuracy: 0.5455\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0274 - accuracy: 0.5479 - val_loss: 0.3630 - val_accuracy: 0.5152\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0388 - accuracy: 0.5441 - val_loss: 0.3284 - val_accuracy: 0.5455\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0302 - accuracy: 0.5594 - val_loss: 0.5472 - val_accuracy: 0.5455\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0621 - accuracy: 0.5670 - val_loss: 0.3041 - val_accuracy: 0.5455\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.5517 - val_loss: 0.3328 - val_accuracy: 0.5758\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0322 - accuracy: 0.5594 - val_loss: 0.3135 - val_accuracy: 0.5455\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0231 - accuracy: 0.5517 - val_loss: 0.3618 - val_accuracy: 0.5152\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0282 - accuracy: 0.5441 - val_loss: 0.3750 - val_accuracy: 0.5152\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0264 - accuracy: 0.5517 - val_loss: 0.3349 - val_accuracy: 0.5152\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0256 - accuracy: 0.5479 - val_loss: 0.4462 - val_accuracy: 0.5152\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0324 - accuracy: 0.5594 - val_loss: 0.4906 - val_accuracy: 0.4848\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0546 - accuracy: 0.5709 - val_loss: 0.3244 - val_accuracy: 0.5455\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.5632 - val_loss: 0.3193 - val_accuracy: 0.5455\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.5517 - val_loss: 0.3241 - val_accuracy: 0.5455\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0210 - accuracy: 0.5594 - val_loss: 0.3658 - val_accuracy: 0.5758\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.5556 - val_loss: 0.3257 - val_accuracy: 0.5152\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0207 - accuracy: 0.5632 - val_loss: 0.3226 - val_accuracy: 0.5758\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0220 - accuracy: 0.5709 - val_loss: 0.3178 - val_accuracy: 0.5455\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0185 - accuracy: 0.5632 - val_loss: 0.3214 - val_accuracy: 0.5455\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0204 - accuracy: 0.5594 - val_loss: 0.3237 - val_accuracy: 0.5455\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0181 - accuracy: 0.5594 - val_loss: 0.3189 - val_accuracy: 0.5455\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0184 - accuracy: 0.5594 - val_loss: 0.3190 - val_accuracy: 0.5455\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0173 - accuracy: 0.5594 - val_loss: 0.3234 - val_accuracy: 0.5455\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0159 - accuracy: 0.5632 - val_loss: 0.4097 - val_accuracy: 0.5455\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.5632 - val_loss: 0.3176 - val_accuracy: 0.5455\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0180 - accuracy: 0.5556 - val_loss: 0.5051 - val_accuracy: 0.4848\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0375 - accuracy: 0.5594 - val_loss: 0.3147 - val_accuracy: 0.5455\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 0.5747 - val_loss: 0.3140 - val_accuracy: 0.5758\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0182 - accuracy: 0.5785 - val_loss: 0.3159 - val_accuracy: 0.5455\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0140 - accuracy: 0.5594 - val_loss: 0.3184 - val_accuracy: 0.5455\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.5594 - val_loss: 0.3215 - val_accuracy: 0.5152\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0143 - accuracy: 0.5556 - val_loss: 0.3296 - val_accuracy: 0.5455\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.5479 - val_loss: 0.3193 - val_accuracy: 0.5152\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.5594 - val_loss: 0.3201 - val_accuracy: 0.5455\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.5556 - val_loss: 0.3193 - val_accuracy: 0.5455\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0140 - accuracy: 0.5632 - val_loss: 0.3612 - val_accuracy: 0.5455\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0240 - accuracy: 0.5747 - val_loss: 0.3402 - val_accuracy: 0.5152\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0186 - accuracy: 0.5632 - val_loss: 0.3153 - val_accuracy: 0.5455\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0125 - accuracy: 0.5709 - val_loss: 0.3180 - val_accuracy: 0.5455\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0119 - accuracy: 0.5709 - val_loss: 0.3203 - val_accuracy: 0.5455\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0120 - accuracy: 0.5670 - val_loss: 0.3195 - val_accuracy: 0.5455\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0138 - accuracy: 0.5670 - val_loss: 0.4565 - val_accuracy: 0.5152\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0396 - accuracy: 0.5824 - val_loss: 0.3405 - val_accuracy: 0.5758\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.5900 - val_loss: 0.3468 - val_accuracy: 0.5758\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0139 - accuracy: 0.5900 - val_loss: 0.3228 - val_accuracy: 0.5455\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 0.5824 - val_loss: 0.3249 - val_accuracy: 0.5455\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.5862 - val_loss: 0.3210 - val_accuracy: 0.5758\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0106 - accuracy: 0.5824 - val_loss: 0.3571 - val_accuracy: 0.5152\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 0.5939 - val_loss: 0.3233 - val_accuracy: 0.5455\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.5709 - val_loss: 0.3210 - val_accuracy: 0.5758\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 0.5785 - val_loss: 0.3218 - val_accuracy: 0.5758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0103 - accuracy: 0.5785 - val_loss: 0.3230 - val_accuracy: 0.5758\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0109 - accuracy: 0.5862 - val_loss: 0.3222 - val_accuracy: 0.5758\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0109 - accuracy: 0.5862 - val_loss: 0.3215 - val_accuracy: 0.5758\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 0.5824 - val_loss: 0.3643 - val_accuracy: 0.5152\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0117 - accuracy: 0.5824 - val_loss: 0.3923 - val_accuracy: 0.5758\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0170 - accuracy: 0.5900 - val_loss: 0.3302 - val_accuracy: 0.5758\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0108 - accuracy: 0.5900 - val_loss: 0.3318 - val_accuracy: 0.5758\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0104 - accuracy: 0.5862 - val_loss: 0.3407 - val_accuracy: 0.5758\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0097 - accuracy: 0.5862 - val_loss: 0.3265 - val_accuracy: 0.5758\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0091 - accuracy: 0.5862 - val_loss: 0.3255 - val_accuracy: 0.5758\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 0.5939 - val_loss: 0.3247 - val_accuracy: 0.5758\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.5977 - val_loss: 0.3259 - val_accuracy: 0.5758\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 0.5939 - val_loss: 0.3936 - val_accuracy: 0.5758\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0197 - accuracy: 0.5939 - val_loss: 0.3171 - val_accuracy: 0.5758\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.5977 - val_loss: 0.3212 - val_accuracy: 0.5758\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0086 - accuracy: 0.5900 - val_loss: 0.3264 - val_accuracy: 0.5758\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.5862 - val_loss: 0.3281 - val_accuracy: 0.5758\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0084 - accuracy: 0.5862 - val_loss: 0.3208 - val_accuracy: 0.5758\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.5862 - val_loss: 0.3247 - val_accuracy: 0.5758\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0080 - accuracy: 0.5824 - val_loss: 0.3232 - val_accuracy: 0.5758\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0078 - accuracy: 0.5862 - val_loss: 0.3256 - val_accuracy: 0.5758\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.5939 - val_loss: 0.3288 - val_accuracy: 0.5758\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 0.5824 - val_loss: 0.3224 - val_accuracy: 0.5758\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 0.5939 - val_loss: 0.3611 - val_accuracy: 0.5758\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0106 - accuracy: 0.5939 - val_loss: 0.3281 - val_accuracy: 0.5758\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 0.5977 - val_loss: 0.3351 - val_accuracy: 0.5455\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.5977 - val_loss: 0.3254 - val_accuracy: 0.5758\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 0.5900 - val_loss: 0.3247 - val_accuracy: 0.5758\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 0.5977 - val_loss: 0.3272 - val_accuracy: 0.5758\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.5900 - val_loss: 0.3256 - val_accuracy: 0.5758\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0080 - accuracy: 0.5939 - val_loss: 0.3233 - val_accuracy: 0.5758\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0067 - accuracy: 0.5977 - val_loss: 0.3263 - val_accuracy: 0.5758\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 0.5939 - val_loss: 0.3224 - val_accuracy: 0.5758\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 0.5939 - val_loss: 0.3222 - val_accuracy: 0.5758\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 0.5900 - val_loss: 0.3288 - val_accuracy: 0.5758\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.5900 - val_loss: 0.3348 - val_accuracy: 0.5758\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.5900 - val_loss: 0.3229 - val_accuracy: 0.5758\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 0.5977 - val_loss: 0.3234 - val_accuracy: 0.5758\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.5939 - val_loss: 0.3562 - val_accuracy: 0.5758\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.5900 - val_loss: 0.3422 - val_accuracy: 0.5758\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.5939 - val_loss: 0.3246 - val_accuracy: 0.5758\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 0.5939 - val_loss: 0.3254 - val_accuracy: 0.5758\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0060 - accuracy: 0.5977 - val_loss: 0.3270 - val_accuracy: 0.5758\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 0.5939 - val_loss: 0.3275 - val_accuracy: 0.5758\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0065 - accuracy: 0.5977 - val_loss: 0.3245 - val_accuracy: 0.5758\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.5977 - val_loss: 0.3266 - val_accuracy: 0.5758\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0057 - accuracy: 0.5824 - val_loss: 0.3246 - val_accuracy: 0.5758\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.5939 - val_loss: 0.3237 - val_accuracy: 0.5455\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.5939 - val_loss: 0.3255 - val_accuracy: 0.5758\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.5785 - val_loss: 0.3227 - val_accuracy: 0.5758\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.5900 - val_loss: 0.3273 - val_accuracy: 0.5758\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 0.5900 - val_loss: 0.3289 - val_accuracy: 0.5758\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0066 - accuracy: 0.5977 - val_loss: 0.3256 - val_accuracy: 0.5758\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.6015 - val_loss: 0.3230 - val_accuracy: 0.5758\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.6015 - val_loss: 0.3244 - val_accuracy: 0.5455\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.5709 - val_loss: 0.3500 - val_accuracy: 0.5455\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0065 - accuracy: 0.5709 - val_loss: 0.3247 - val_accuracy: 0.5455\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.5747 - val_loss: 0.3296 - val_accuracy: 0.5758\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.5824 - val_loss: 0.3257 - val_accuracy: 0.5758\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.5900 - val_loss: 0.3233 - val_accuracy: 0.5758\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0048 - accuracy: 0.5900 - val_loss: 0.3243 - val_accuracy: 0.5455\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.5900 - val_loss: 0.3236 - val_accuracy: 0.5758\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.5977 - val_loss: 0.3247 - val_accuracy: 0.5758\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.5939 - val_loss: 0.3249 - val_accuracy: 0.5758\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 0.6015 - val_loss: 0.3276 - val_accuracy: 0.5758\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0051 - accuracy: 0.5977 - val_loss: 0.3233 - val_accuracy: 0.5758\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0047 - accuracy: 0.5900 - val_loss: 0.3249 - val_accuracy: 0.5758\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.5977 - val_loss: 0.3261 - val_accuracy: 0.5455\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.6015 - val_loss: 0.3241 - val_accuracy: 0.5758\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.5977 - val_loss: 0.3261 - val_accuracy: 0.5758\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 0.5977 - val_loss: 0.3261 - val_accuracy: 0.5758\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.5939 - val_loss: 0.3243 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.4848\n",
      "Test accuracy: 0.4848484992980957\n"
     ]
    }
   ],
   "source": [
    "# Anagha's Implementation\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(10, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "#     layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(5, activation='softmax'),\n",
    "    layers.Dense(2)  # Use 2 output units for binary classification\n",
    "])\n",
    "\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss=['mse'],\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "\n",
    "# Step 3: Train and evaluate model\n",
    "\n",
    "history2 = model.fit(X_train, Y_train, epochs=300, batch_size=20, \n",
    "                    validation_data=(X_val, Y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9c1852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['accuracy'], label='train')\n",
    "plt.plot(history2.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "195cf72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 67ms/step - loss: 0.7620 - accuracy: 0.5249 - val_loss: 0.7589 - val_accuracy: 0.4848\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7307 - accuracy: 0.5670 - val_loss: 0.7562 - val_accuracy: 0.4545\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.7255 - accuracy: 0.5479 - val_loss: 0.7504 - val_accuracy: 0.4545\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.7078 - accuracy: 0.5556 - val_loss: 0.7489 - val_accuracy: 0.4848\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6999 - accuracy: 0.5747 - val_loss: 0.7361 - val_accuracy: 0.5455\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.6921 - accuracy: 0.6207 - val_loss: 0.7268 - val_accuracy: 0.5758\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.6882 - accuracy: 0.6284 - val_loss: 0.7252 - val_accuracy: 0.5758\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.6744 - accuracy: 0.6437 - val_loss: 0.7273 - val_accuracy: 0.5152\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6623 - accuracy: 0.6284 - val_loss: 0.7182 - val_accuracy: 0.5455\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6510 - accuracy: 0.6667 - val_loss: 0.7174 - val_accuracy: 0.5455\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.6594 - accuracy: 0.6858 - val_loss: 0.7203 - val_accuracy: 0.5152\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.6421 - accuracy: 0.7011 - val_loss: 0.7169 - val_accuracy: 0.5758\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6387 - accuracy: 0.6897 - val_loss: 0.7251 - val_accuracy: 0.5152\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6399 - accuracy: 0.6475 - val_loss: 0.7510 - val_accuracy: 0.5455\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6149 - accuracy: 0.7050 - val_loss: 0.7231 - val_accuracy: 0.6061\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6306 - accuracy: 0.7165 - val_loss: 0.7221 - val_accuracy: 0.6061\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6042 - accuracy: 0.7318 - val_loss: 0.7289 - val_accuracy: 0.5455\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5986 - accuracy: 0.7126 - val_loss: 0.7173 - val_accuracy: 0.6061\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5945 - accuracy: 0.7931 - val_loss: 0.7124 - val_accuracy: 0.6061\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.5869 - accuracy: 0.7395 - val_loss: 0.7176 - val_accuracy: 0.6061\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5773 - accuracy: 0.7816 - val_loss: 0.7130 - val_accuracy: 0.6061\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5689 - accuracy: 0.7625 - val_loss: 0.7235 - val_accuracy: 0.5455\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.5668 - accuracy: 0.7816 - val_loss: 0.7174 - val_accuracy: 0.6061\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5666 - accuracy: 0.7663 - val_loss: 0.7209 - val_accuracy: 0.5758\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5430 - accuracy: 0.7663 - val_loss: 0.7340 - val_accuracy: 0.5152\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5518 - accuracy: 0.7471 - val_loss: 0.7240 - val_accuracy: 0.6061\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5384 - accuracy: 0.7931 - val_loss: 0.7200 - val_accuracy: 0.6061\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5426 - accuracy: 0.7625 - val_loss: 0.7314 - val_accuracy: 0.5152\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5291 - accuracy: 0.8084 - val_loss: 0.7198 - val_accuracy: 0.5758\n",
      "2/2 [==============================] - 0s 0s/step - loss: 0.6387 - accuracy: 0.7576\n",
      "Test accuracy: 0.7575757503509521\n"
     ]
    }
   ],
   "source": [
    "# Anagha's Implementation\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(5, (3,3), activation='relu', input_shape=(32, 32, 3), kernel_regularizer=tf.keras.regularizers.l2(l=0.01)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(2, activation='sigmoid')  # Use 2 output units for binary classification\n",
    "])\n",
    "\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    ")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Step 3: Train and evaluate model\n",
    "\n",
    "history2 = model.fit(X_train, Y_train, epochs=200, batch_size=60, \n",
    "                    validation_data=(X_val, Y_val), callbacks=[callback])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d06d407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['accuracy'], label='train')\n",
    "plt.plot(history2.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f89f533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 4.1200 - accuracy: 0.5709 - val_loss: 5.0842 - val_accuracy: 0.5152\n",
      "Epoch 2/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.0831 - accuracy: 0.5709 - val_loss: 4.5423 - val_accuracy: 0.5152\n",
      "Epoch 3/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 4.0241 - accuracy: 0.5709 - val_loss: 4.6308 - val_accuracy: 0.5152\n",
      "Epoch 4/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 4.0083 - accuracy: 0.5709 - val_loss: 4.6325 - val_accuracy: 0.5152\n",
      "Epoch 5/400\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 3.9327 - accuracy: 0.5709 - val_loss: 4.6258 - val_accuracy: 0.5152\n",
      "Epoch 6/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.9306 - accuracy: 0.5709 - val_loss: 4.6231 - val_accuracy: 0.5152\n",
      "Epoch 7/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.9017 - accuracy: 0.5709 - val_loss: 4.4525 - val_accuracy: 0.5152\n",
      "Epoch 8/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8909 - accuracy: 0.5709 - val_loss: 4.6178 - val_accuracy: 0.5152\n",
      "Epoch 9/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.9023 - accuracy: 0.5709 - val_loss: 4.4065 - val_accuracy: 0.5152\n",
      "Epoch 10/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.9001 - accuracy: 0.5709 - val_loss: 4.4011 - val_accuracy: 0.5152\n",
      "Epoch 11/400\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 3.8771 - accuracy: 0.5709 - val_loss: 4.4140 - val_accuracy: 0.5152\n",
      "Epoch 12/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8914 - accuracy: 0.5709 - val_loss: 4.3960 - val_accuracy: 0.5152\n",
      "Epoch 13/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8764 - accuracy: 0.5709 - val_loss: 4.4084 - val_accuracy: 0.5152\n",
      "Epoch 14/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8675 - accuracy: 0.5709 - val_loss: 4.4008 - val_accuracy: 0.5152\n",
      "Epoch 15/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8704 - accuracy: 0.5709 - val_loss: 4.4068 - val_accuracy: 0.5152\n",
      "Epoch 16/400\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 3.9117 - accuracy: 0.5709 - val_loss: 4.4009 - val_accuracy: 0.5152\n",
      "Epoch 17/400\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 3.8890 - accuracy: 0.5709 - val_loss: 4.3772 - val_accuracy: 0.5152\n",
      "Epoch 18/400\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 3.8715 - accuracy: 0.5709 - val_loss: 4.3761 - val_accuracy: 0.5152\n",
      "Epoch 19/400\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 3.8720 - accuracy: 0.5709 - val_loss: 4.3762 - val_accuracy: 0.5152\n",
      "Epoch 20/400\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 3.8620 - accuracy: 0.5709 - val_loss: 4.3818 - val_accuracy: 0.5152\n",
      "Epoch 21/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8605 - accuracy: 0.5709 - val_loss: 4.3807 - val_accuracy: 0.5152\n",
      "Epoch 22/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8586 - accuracy: 0.5709 - val_loss: 4.3786 - val_accuracy: 0.5152\n",
      "Epoch 23/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8513 - accuracy: 0.5709 - val_loss: 4.3818 - val_accuracy: 0.5152\n",
      "Epoch 24/400\n",
      "27/27 [==============================] - 0s 11ms/step - loss: 3.8437 - accuracy: 0.5709 - val_loss: 4.3922 - val_accuracy: 0.5152\n",
      "Epoch 25/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8400 - accuracy: 0.5709 - val_loss: 4.3820 - val_accuracy: 0.5152\n",
      "Epoch 26/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8399 - accuracy: 0.5709 - val_loss: 4.3992 - val_accuracy: 0.5152\n",
      "Epoch 27/400\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 3.8347 - accuracy: 0.5709 - val_loss: 4.4326 - val_accuracy: 0.5152\n",
      "Epoch 28/400\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 3.8299 - accuracy: 0.5709 - val_loss: 4.3839 - val_accuracy: 0.5152\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.8427 - accuracy: 0.5758\n",
      "Test accuracy: 0.5757575631141663\n"
     ]
    }
   ],
   "source": [
    "# Anagha's Implementation\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(5, (3,3), activation='relu', input_shape=(32, 32, 3), kernel_regularizer=tf.keras.regularizers.l2(l=0.01)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(2, activation='relu')  # Use 2 output units for binary classification\n",
    "])\n",
    "\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss=tf.keras.losses.Poisson(reduction=\"auto\", name=\"poisson\"),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Step 3: Train and evaluate model\n",
    "\n",
    "history2 = model.fit(X_train, Y_train, epochs=400, batch_size=10, \n",
    "                    validation_data=(X_val, Y_val), callbacks=[callback])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1fe0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history2.history['accuracy'], label='train')\n",
    "plt.plot(history2.history['val_accuracy'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffe251",
   "metadata": {},
   "source": [
    "## Comapring the results of all the tests in tabular format by Leelakrishna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "605287ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame([[0.5757, 1.7832 , 0.5455, 2.7708, 'Null', 32, 0.1, 500, 'SGD', 'relu', 'SparseCategoricalCrossentropy',8],\n",
    "        [0.3030, 0.1925, 0.5152, 0.3631, 'Null', 50, 0.01, 400, 'Adam', 'relu', 'mse', 5],\n",
    "        [0.4848, 0.2723, 0.5455, 0.3736, 'Null', 20, 0.001, 300, 'SGD', 'relu|softmax', 'mse', 4],\n",
    "        [0.6573, 0.6705, 0.4848, 0.7693, 0.2, 60, 0.001, 200, 'Adam', 'relu|sigmoid', 'SparseCategoricalCrossentropy', 5],\n",
    "        [0.5152, 0.6889, 0.6667, 0.89, 0.2, 10, 0.1, 400, 'Adam', 'relu', 'poisson', 5],\n",
    "        [0.0690, 6.2492, 0.0606, 6.2893, 'Null', '', 0.001, 10, 'Adam', 'relu', 'CrossEntropyLoss', 1]],\n",
    "                    columns=['Train_Accuracy', 'Train_Loss', 'Val_Accuracy', 'Val_Loss', 'Dropout','Batch size', 'LR', 'Epochs', \n",
    "                             'Optimizer', 'Activation', 'Loss', 'Layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fe3a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy</th>\n",
       "      <th>Train_Loss</th>\n",
       "      <th>Val_Accuracy</th>\n",
       "      <th>Val_Loss</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>LR</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5757</td>\n",
       "      <td>1.7832</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>2.7708</td>\n",
       "      <td>Null</td>\n",
       "      <td>32</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>SGD</td>\n",
       "      <td>relu</td>\n",
       "      <td>SparseCategoricalCrossentropy</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.3631</td>\n",
       "      <td>Null</td>\n",
       "      <td>50</td>\n",
       "      <td>0.010</td>\n",
       "      <td>400</td>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>mse</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.3736</td>\n",
       "      <td>Null</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>300</td>\n",
       "      <td>SGD</td>\n",
       "      <td>relu|softmax</td>\n",
       "      <td>mse</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6573</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.7693</td>\n",
       "      <td>0.2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.001</td>\n",
       "      <td>200</td>\n",
       "      <td>Adam</td>\n",
       "      <td>relu|sigmoid</td>\n",
       "      <td>SparseCategoricalCrossentropy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>400</td>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0690</td>\n",
       "      <td>6.2492</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>6.2893</td>\n",
       "      <td>Null</td>\n",
       "      <td></td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>Adam</td>\n",
       "      <td>relu</td>\n",
       "      <td>CrossEntropyLoss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train_Accuracy  Train_Loss  Val_Accuracy  Val_Loss Dropout Batch size  \\\n",
       "0          0.5757      1.7832        0.5455    2.7708    Null         32   \n",
       "1          0.3030      0.1925        0.5152    0.3631    Null         50   \n",
       "2          0.4848      0.2723        0.5455    0.3736    Null         20   \n",
       "3          0.6573      0.6705        0.4848    0.7693     0.2         60   \n",
       "4          0.5152      0.6889        0.6667    0.8900     0.2         10   \n",
       "5          0.0690      6.2492        0.0606    6.2893    Null              \n",
       "\n",
       "      LR  Epochs Optimizer    Activation                           Loss  \\\n",
       "0  0.100     500       SGD          relu  SparseCategoricalCrossentropy   \n",
       "1  0.010     400      Adam          relu                            mse   \n",
       "2  0.001     300       SGD  relu|softmax                            mse   \n",
       "3  0.001     200      Adam  relu|sigmoid  SparseCategoricalCrossentropy   \n",
       "4  0.100     400      Adam          relu                        poisson   \n",
       "5  0.001      10      Adam          relu               CrossEntropyLoss   \n",
       "\n",
       "   Layers  \n",
       "0       8  \n",
       "1       5  \n",
       "2       4  \n",
       "3       5  \n",
       "4       5  \n",
       "5       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Test Results\")\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897d0ad",
   "metadata": {},
   "source": [
    "In the above table, the last observation is obtained from custom CNN. Also various tests were carried out but while doing it we forgot to note the results and only a few were listed here. All of them were facing overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a544e",
   "metadata": {},
   "source": [
    "# How to change the code to work over 1-Dimensional data? \n",
    "We would only need 1 for loop in out custom layer and that just goes across one row. The pooling layer would only be 1 \n",
    "dimension.\n",
    "\n",
    "# How to change the code to work over 3-Dimensional data?\n",
    "We would need another nested for loop in our custom layer to account for the extra dimension. The pooling layer would be 3 dimensions in the combined network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc1d97",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c05c8",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/building-a-convolutional-neural-network-from-scratch-using-numpy-a22808a00a40\n",
    "\n",
    "https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/\n",
    "\n",
    "https://medium.com/thecyphy/train-cnn-model-with-pytorch-21dafb918f48\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/cnn\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/09/overfitting-in-cnn-show-to-treat-overfitting-in-convolutional-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5446690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
